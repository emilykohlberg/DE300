{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e7f5c5-1f5e-4773-8950-66be75241122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, FloatType, LongType, StringType, DoubleType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f0ac94-ae99-42c8-8528-3b62b4e191ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a5270-37a8-4a0e-9663-2f0c09b88269",
   "metadata": {},
   "source": [
    "## Check Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06b828d-1d7a-41a3-8929-703028401ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/demos/bin/python3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12fef7f-59b8-4b2b-b7b6-f2fff328616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "NUMBER_OF_FOLDS = 3\n",
    "SPLIT_SEED = 7576\n",
    "TRAIN_TEST_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a794b4a-3efa-48bc-a8c3-2df602c90670",
   "metadata": {},
   "source": [
    "## Function for data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ab6c2d-df8f-4aaf-bdfe-a6f30efaba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    read data; since the data has the header we let spark guess the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the Titanic CSV data into a DataFrame\n",
    "    titanic_data = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(os.path.join(DATA_FOLDER,\"*.csv\"))\n",
    "\n",
    "    return titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6afbb-f7ce-4f7a-897b-070bfb496efe",
   "metadata": {},
   "source": [
    "## Writing new Transformer type class : adding cross product of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef9e877-a67b-4757-96d6-571c8fc02579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseProduct(Transformer):\n",
    "\n",
    "    def __init__(self, inputCols, outputCols):\n",
    "        self.__inputCols = inputCols\n",
    "        self.__outputCols = outputCols\n",
    "\n",
    "        self._paramMap = self._params = {}\n",
    "\n",
    "    def _transform(self, df):\n",
    "        for cols, out_col in zip(self.__inputCols, self.__outputCols):\n",
    "            df = df.withColumn(out_col, col(cols[0]) * col(cols[1]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7f7448-ee10-42fb-bbb9-4d56f1225536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredFeatures(Transformer):\n",
    "\n",
    "    def __init__(self, inputCols, outputCols):\n",
    "        self.__inputCols = inputCols\n",
    "        self.__outputCols = outputCols\n",
    "\n",
    "        self._paramMap = self._params = {}\n",
    "\n",
    "    def _transform(self, df):\n",
    "        for c, out_col in zip(self.__inputCols, self.__outputCols):\n",
    "            df = df.withColumn(out_col, col(c) ** 2)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da37d86-c3aa-43c2-a838-7b072140259e",
   "metadata": {},
   "source": [
    "## The ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a6c908-cfc7-431e-a19e-080b41efb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pipeline(data: DataFrame):\n",
    "\n",
    "    \"\"\"\n",
    "    every attribute that is numeric is non-categorical; this is questionable\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_features = [f.name for f in data.schema.fields if isinstance(f.dataType, DoubleType) or isinstance(f.dataType, FloatType) or isinstance(f.dataType, IntegerType) or isinstance(f.dataType, LongType)]\n",
    "    string_features = [f.name for f in data.schema.fields if isinstance(f.dataType, StringType)]\n",
    "    numeric_features.remove(\"PassengerId\")\n",
    "    numeric_features.remove(\"Survived\")\n",
    "    string_features.remove(\"Name\")\n",
    "\n",
    "    # index string features; map string to consecutive integers - it should be one hot encoding \n",
    "    name_indexed_string_columns = [f\"{v}Index\" for v in string_features] \n",
    "    # we must have keep so that we can impute them in the next step\n",
    "    indexer = StringIndexer(inputCols=string_features, outputCols=name_indexed_string_columns, handleInvalid='keep')\n",
    "\n",
    "    # Fill missing values; strategy can be mode, median, mean\n",
    "    \n",
    "    # string columns\n",
    "    imputed_columns_string = [f\"Imputed{v}\" for v in name_indexed_string_columns]\n",
    "    imputers_string = []\n",
    "    for org_col_name, indexed_col_name, imputed_col_name in zip(string_features, name_indexed_string_columns, imputed_columns_string):\n",
    "        # Count the number of distinct categories in the original column\n",
    "        number_of_categories = data.select(F.countDistinct(org_col_name)).take(1)[0].asDict()[f'count(DISTINCT {org_col_name})']\n",
    "        \n",
    "        # Create an imputer for the indexed column\n",
    "        # this is the value that needs to be imputed based on the keep option above\n",
    "        imputer = Imputer(inputCol=indexed_col_name, outputCol=imputed_col_name, strategy = \"mode\", missingValue=number_of_categories)\n",
    "\n",
    "        # Append the imputer to the list\n",
    "        imputers_string.append(imputer)\n",
    "\n",
    "    \n",
    "    # numeric columns\n",
    "    imputed_columns_numeric = [f\"Imputed{v}\" for v in numeric_features]\n",
    "    imputer_numeric = Imputer(inputCols=numeric_features, outputCols=imputed_columns_numeric, strategy = \"mean\")\n",
    "\n",
    "    # Create all pairwise products of numeric features\n",
    "    all_pairs = [v for v in combinations(imputed_columns_numeric, 2)]\n",
    "    pairwise_columns = [f\"{col1}_{col2}\" for col1, col2 in all_pairs]\n",
    "    pairwise_product = PairwiseProduct(inputCols=all_pairs, outputCols=pairwise_columns)\n",
    "\n",
    "     # Create all squared products of numeric features\n",
    "    squared_columns = [f\"{col}_squared\" for col in imputed_columns_numeric]\n",
    "    squared_product = SquaredFeatures(inputCols=imputed_columns_numeric, outputCols=squared_columns)\n",
    "\n",
    "\n",
    "\n",
    "    # Assemble feature columns into a single feature vector\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=pairwise_columns + squared_columns + imputed_columns_numeric + imputed_columns_string, \n",
    "        outputCol=\"features\"\n",
    "        )\n",
    "\n",
    "    # Define a Random Forest classifier\n",
    "    classifier = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(stages=[indexer, *imputers_string, imputer_numeric, pairwise_product,squared_product, assembler, classifier])\n",
    "    \n",
    "    # Set up the parameter grid for maximum tree depth\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(classifier.maxDepth, [2, 4, 6, 8, 10]) \\\n",
    "        .addGrid(classifier.numTrees, [150, 200, 250, 500]) \\\n",
    "        .build()\n",
    "\n",
    "    # Set up the cross-validator\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=NUMBER_OF_FOLDS,\n",
    "        seed=SPLIT_SEED)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = data.randomSplit([TRAIN_TEST_SPLIT, 1-TRAIN_TEST_SPLIT], seed=SPLIT_SEED)\n",
    "\n",
    "    # Train the cross-validated pipeline model\n",
    "    cvModel = crossval.fit(train_data)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = cvModel.transform(test_data)\n",
    "\n",
    "    # Evaluate the model\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    print(f\"Area Under ROC Curve: {auc:.4f}\")\n",
    "\n",
    "    # Get the best RandomForest model\n",
    "    best_model = cvModel.bestModel.stages[-1]\n",
    "\n",
    "    # Retrieve the selected maximum tree depth\n",
    "    selected_max_depth = best_model.getOrDefault(best_model.getParam(\"maxDepth\"))\n",
    "\n",
    "    # Print the selected maximum tree depth\n",
    "    print(f\"Selected Maximum Tree Depth: {selected_max_depth}\")\n",
    "\n",
    "    # Retrieve the selected number of trees\n",
    "    selected_num_trees = best_model.getOrDefault(best_model.getParam(\"numTrees\"))\n",
    "\n",
    "    # Print the selected number of trees\n",
    "    print(f\"Selected Number of Trees: {selected_num_trees}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d53e22-eb2c-4e85-bf7f-12ec742721a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315b3402-ad5f-4e46-a317-e0c3d804963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/20 02:12:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/20 02:13:49 WARN DAGScheduler: Broadcasting large task binary with size 1311.7 KiB\n",
      "24/05/20 02:14:16 WARN DAGScheduler: Broadcasting large task binary with size 1132.1 KiB\n",
      "24/05/20 02:14:18 WARN DAGScheduler: Broadcasting large task binary with size 1819.1 KiB\n",
      "24/05/20 02:14:30 WARN DAGScheduler: Broadcasting large task binary with size 1263.7 KiB\n",
      "24/05/20 02:14:31 WARN DAGScheduler: Broadcasting large task binary with size 1263.5 KiB\n",
      "24/05/20 02:14:36 WARN DAGScheduler: Broadcasting large task binary with size 1027.6 KiB\n",
      "24/05/20 02:14:36 WARN DAGScheduler: Broadcasting large task binary with size 1533.0 KiB\n",
      "24/05/20 02:14:38 WARN DAGScheduler: Broadcasting large task binary with size 1538.4 KiB\n",
      "24/05/20 02:14:42 WARN DAGScheduler: Broadcasting large task binary with size 1132.1 KiB\n",
      "24/05/20 02:14:43 WARN DAGScheduler: Broadcasting large task binary with size 1875.8 KiB\n",
      "24/05/20 02:14:44 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:14:46 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:14:51 WARN DAGScheduler: Broadcasting large task binary with size 1354.2 KiB\n",
      "24/05/20 02:14:51 WARN DAGScheduler: Broadcasting large task binary with size 1734.6 KiB\n",
      "24/05/20 02:14:52 WARN DAGScheduler: Broadcasting large task binary with size 1393.5 KiB\n",
      "24/05/20 02:14:57 WARN DAGScheduler: Broadcasting large task binary with size 1263.7 KiB\n",
      "24/05/20 02:14:57 WARN DAGScheduler: Broadcasting large task binary with size 1729.2 KiB\n",
      "24/05/20 02:14:58 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1804.0 KiB\n",
      "24/05/20 02:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1027.6 KiB\n",
      "24/05/20 02:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1533.0 KiB\n",
      "24/05/20 02:15:05 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:15:05 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/20 02:15:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1132.1 KiB\n",
      "24/05/20 02:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1875.8 KiB\n",
      "24/05/20 02:15:12 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:15:13 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/05/20 02:15:14 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/05/20 02:15:17 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/05/20 02:15:21 WARN DAGScheduler: Broadcasting large task binary with size 1354.2 KiB\n",
      "24/05/20 02:15:22 WARN DAGScheduler: Broadcasting large task binary with size 1734.6 KiB\n",
      "24/05/20 02:15:22 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/20 02:15:23 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/20 02:15:27 WARN DAGScheduler: Broadcasting large task binary with size 1734.1 KiB\n",
      "24/05/20 02:15:31 WARN DAGScheduler: Broadcasting large task binary with size 1263.7 KiB\n",
      "24/05/20 02:15:32 WARN DAGScheduler: Broadcasting large task binary with size 1729.2 KiB\n",
      "24/05/20 02:15:33 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:15:33 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/20 02:15:34 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/20 02:15:35 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:15:39 WARN DAGScheduler: Broadcasting large task binary with size 1027.6 KiB\n",
      "24/05/20 02:15:40 WARN DAGScheduler: Broadcasting large task binary with size 1533.0 KiB\n",
      "24/05/20 02:15:41 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:15:41 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/20 02:15:42 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/05/20 02:15:43 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/05/20 02:15:45 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/20 02:15:48 WARN DAGScheduler: Broadcasting large task binary with size 1132.1 KiB\n",
      "24/05/20 02:15:49 WARN DAGScheduler: Broadcasting large task binary with size 1875.8 KiB\n",
      "24/05/20 02:15:50 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:15:51 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/05/20 02:15:52 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/05/20 02:15:54 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "24/05/20 02:15:55 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n",
      "24/05/20 02:15:57 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "24/05/20 02:16:14 WARN DAGScheduler: Broadcasting large task binary with size 1321.2 KiB\n",
      "24/05/20 02:16:27 WARN DAGScheduler: Broadcasting large task binary with size 1014.5 KiB\n",
      "24/05/20 02:16:30 WARN DAGScheduler: Broadcasting large task binary with size 1154.9 KiB\n",
      "24/05/20 02:16:32 WARN DAGScheduler: Broadcasting large task binary with size 1863.6 KiB\n",
      "24/05/20 02:16:35 WARN DAGScheduler: Broadcasting large task binary with size 1026.4 KiB\n",
      "24/05/20 02:16:36 WARN DAGScheduler: Broadcasting large task binary with size 1017.0 KiB\n",
      "24/05/20 02:16:39 WARN DAGScheduler: Broadcasting large task binary with size 1312.6 KiB\n",
      "24/05/20 02:16:41 WARN DAGScheduler: Broadcasting large task binary with size 1305.4 KiB\n",
      "24/05/20 02:16:44 WARN DAGScheduler: Broadcasting large task binary with size 1072.9 KiB\n",
      "24/05/20 02:16:44 WARN DAGScheduler: Broadcasting large task binary with size 1618.6 KiB\n",
      "24/05/20 02:16:46 WARN DAGScheduler: Broadcasting large task binary with size 1604.9 KiB\n",
      "24/05/20 02:16:49 WARN DAGScheduler: Broadcasting large task binary with size 1154.9 KiB\n",
      "24/05/20 02:16:49 WARN DAGScheduler: Broadcasting large task binary with size 1962.6 KiB\n",
      "24/05/20 02:16:50 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/20 02:16:52 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/20 02:16:56 WARN DAGScheduler: Broadcasting large task binary with size 1026.4 KiB\n",
      "24/05/20 02:16:56 WARN DAGScheduler: Broadcasting large task binary with size 1406.1 KiB\n",
      "24/05/20 02:16:56 WARN DAGScheduler: Broadcasting large task binary with size 1801.3 KiB\n",
      "24/05/20 02:16:57 WARN DAGScheduler: Broadcasting large task binary with size 1448.9 KiB\n",
      "24/05/20 02:17:00 WARN DAGScheduler: Broadcasting large task binary with size 1312.6 KiB\n",
      "24/05/20 02:17:01 WARN DAGScheduler: Broadcasting large task binary with size 1803.8 KiB\n",
      "24/05/20 02:17:01 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/20 02:17:02 WARN DAGScheduler: Broadcasting large task binary with size 1858.0 KiB\n",
      "24/05/20 02:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1072.9 KiB\n",
      "24/05/20 02:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1618.6 KiB\n",
      "24/05/20 02:17:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/20 02:17:12 WARN DAGScheduler: Broadcasting large task binary with size 1154.9 KiB\n",
      "24/05/20 02:17:13 WARN DAGScheduler: Broadcasting large task binary with size 1962.6 KiB\n",
      "24/05/20 02:17:14 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/20 02:17:15 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/05/20 02:17:16 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "24/05/20 02:17:18 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "24/05/20 02:17:21 WARN DAGScheduler: Broadcasting large task binary with size 1026.4 KiB\n",
      "24/05/20 02:17:22 WARN DAGScheduler: Broadcasting large task binary with size 1406.0 KiB\n",
      "24/05/20 02:17:22 WARN DAGScheduler: Broadcasting large task binary with size 1801.3 KiB\n",
      "24/05/20 02:17:22 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:17:23 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/05/20 02:17:24 WARN DAGScheduler: Broadcasting large task binary with size 1798.5 KiB\n",
      "24/05/20 02:17:27 WARN DAGScheduler: Broadcasting large task binary with size 1312.6 KiB\n",
      "24/05/20 02:17:27 WARN DAGScheduler: Broadcasting large task binary with size 1803.8 KiB\n",
      "24/05/20 02:17:28 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/20 02:17:29 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/20 02:17:30 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/20 02:17:31 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/20 02:17:34 WARN DAGScheduler: Broadcasting large task binary with size 1072.9 KiB\n",
      "24/05/20 02:17:34 WARN DAGScheduler: Broadcasting large task binary with size 1618.6 KiB\n",
      "24/05/20 02:17:35 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:17:35 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:17:36 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/20 02:17:37 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/05/20 02:17:38 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:17:41 WARN DAGScheduler: Broadcasting large task binary with size 1154.9 KiB\n",
      "24/05/20 02:17:42 WARN DAGScheduler: Broadcasting large task binary with size 1962.6 KiB\n",
      "24/05/20 02:17:43 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/20 02:17:44 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/05/20 02:17:45 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "24/05/20 02:17:47 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "24/05/20 02:17:48 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "24/05/20 02:17:50 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "24/05/20 02:18:17 WARN DAGScheduler: Broadcasting large task binary with size 1321.8 KiB\n",
      "24/05/20 02:18:28 WARN DAGScheduler: Broadcasting large task binary with size 1012.3 KiB\n",
      "24/05/20 02:18:31 WARN DAGScheduler: Broadcasting large task binary with size 1138.5 KiB\n",
      "24/05/20 02:18:33 WARN DAGScheduler: Broadcasting large task binary with size 1869.5 KiB\n",
      "24/05/20 02:18:40 WARN DAGScheduler: Broadcasting large task binary with size 1270.1 KiB\n",
      "24/05/20 02:18:41 WARN DAGScheduler: Broadcasting large task binary with size 1289.2 KiB\n",
      "24/05/20 02:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1040.0 KiB\n",
      "24/05/20 02:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1537.1 KiB\n",
      "24/05/20 02:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1552.4 KiB\n",
      "24/05/20 02:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1138.5 KiB\n",
      "24/05/20 02:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1897.1 KiB\n",
      "24/05/20 02:18:51 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:18:52 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/05/20 02:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1314.9 KiB\n",
      "24/05/20 02:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1667.8 KiB\n",
      "24/05/20 02:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1374.6 KiB\n",
      "24/05/20 02:19:00 WARN DAGScheduler: Broadcasting large task binary with size 1270.1 KiB\n",
      "24/05/20 02:19:00 WARN DAGScheduler: Broadcasting large task binary with size 1723.8 KiB\n",
      "24/05/20 02:19:01 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:19:02 WARN DAGScheduler: Broadcasting large task binary with size 1786.2 KiB\n",
      "24/05/20 02:19:06 WARN DAGScheduler: Broadcasting large task binary with size 1040.0 KiB\n",
      "24/05/20 02:19:06 WARN DAGScheduler: Broadcasting large task binary with size 1537.1 KiB\n",
      "24/05/20 02:19:07 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/20 02:19:07 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/20 02:19:08 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:19:12 WARN DAGScheduler: Broadcasting large task binary with size 1138.5 KiB\n",
      "24/05/20 02:19:12 WARN DAGScheduler: Broadcasting large task binary with size 1897.1 KiB\n",
      "24/05/20 02:19:13 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:19:14 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/05/20 02:19:15 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/05/20 02:19:17 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/05/20 02:19:21 WARN DAGScheduler: Broadcasting large task binary with size 1314.9 KiB\n",
      "24/05/20 02:19:21 WARN DAGScheduler: Broadcasting large task binary with size 1667.8 KiB\n",
      "24/05/20 02:19:21 WARN DAGScheduler: Broadcasting large task binary with size 1998.8 KiB\n",
      "24/05/20 02:19:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/20 02:19:23 WARN DAGScheduler: Broadcasting large task binary with size 1694.3 KiB\n",
      "24/05/20 02:19:26 WARN DAGScheduler: Broadcasting large task binary with size 1270.1 KiB\n",
      "24/05/20 02:19:27 WARN DAGScheduler: Broadcasting large task binary with size 1723.8 KiB\n",
      "24/05/20 02:19:27 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:19:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/20 02:19:28 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/05/20 02:19:29 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/20 02:19:33 WARN DAGScheduler: Broadcasting large task binary with size 1040.0 KiB\n",
      "24/05/20 02:19:33 WARN DAGScheduler: Broadcasting large task binary with size 1537.1 KiB\n",
      "24/05/20 02:19:34 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/20 02:19:34 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/20 02:19:35 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/20 02:19:35 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/05/20 02:19:37 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/20 02:19:39 WARN DAGScheduler: Broadcasting large task binary with size 1138.5 KiB\n",
      "24/05/20 02:19:40 WARN DAGScheduler: Broadcasting large task binary with size 1897.1 KiB\n",
      "24/05/20 02:19:41 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/20 02:19:42 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/05/20 02:19:43 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/05/20 02:19:44 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "24/05/20 02:19:46 WARN DAGScheduler: Broadcasting large task binary with size 7.1 MiB\n",
      "24/05/20 02:19:48 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/05/20 02:19:57 WARN DAGScheduler: Broadcasting large task binary with size 1083.2 KiB\n",
      "24/05/20 02:19:58 WARN DAGScheduler: Broadcasting large task binary with size 1687.3 KiB\n",
      "24/05/20 02:20:00 WARN DAGScheduler: Broadcasting large task binary with size 1649.2 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve: 0.8948\n",
      "Selected Maximum Tree Depth: 6\n",
      "Selected Number of Trees: 250\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Predict Titanic Survival\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    data = read_data(spark)\n",
    "    pipeline(data)\n",
    "\n",
    "    spark.stop()\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
