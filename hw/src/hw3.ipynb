{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2336782c-4ac0-483d-bb5d-672220c6035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "# import pandas as pd\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import psycopg2\n",
    "\n",
    "#required for navigating machine's directory\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, FloatType, LongType, StringType, DoubleType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when, col\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eac28b-5d93-4a3a-b30b-3afc5dda624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "\n",
    "NUMBER_OF_FOLDS = 3\n",
    "SPLIT_SEED = 7576\n",
    "TRAIN_TEST_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd295f28-eb11-445f-90ee-081db6e2941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 17:27:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Exception ignored in: <function JavaWrapper.__del__ at 0x71c1f15657e0>          \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/demos/lib/python3.10/site-packages/pyspark/ml/wrapper.py\", line 53, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'Imputer' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+--------+---+--------+---+----+----+---+--------+-------+-------+-----+-------+-----+------+-------+-------------------+\n",
      "|age|sex|painloc|painexer| cp|trestbps|fbs|prop|nitr|pro|diuretic|thaldur|thalach|exang|oldpeak|slope|target|smoke_1|            smoke_2|\n",
      "+---+---+-------+--------+---+--------+---+----+----+---+--------+-------+-------+-----+-------+-----+------+-------+-------------------+\n",
      "| 63|  1|   null|    null|  1|     145|  1|   0|   0|  0|       0|   10.5|    150|    0|    2.3|    3|     0|  0.149|0.19325742574257426|\n",
      "| 67|  1|   null|    null|  4|     160|  0|   1|   0|  0|       0|    9.5|    108|    1|    1.5|    2|     1|  0.087|0.10765346534653465|\n",
      "| 67|  1|   null|    null|  4|     120|  0|   1|   0|  0|       0|    8.5|    129|    1|    2.6|    2|     1|  0.087|0.10765346534653465|\n",
      "| 37|  1|   null|    null|  3|     130|  0|   1|   0|  0|       0|   13.0|    187|    0|    3.5|    3|     0|  0.109|0.16342574257425743|\n",
      "| 41|  0|   null|    null|  2|     130|  0|   0|   0|  0|       0|    7.0|    172|    0|    1.4|    1|     0|  0.109|              0.126|\n",
      "| 56|  1|   null|    null|  2|     120|  0|   0|   0|  0|       0|   11.3|    178|    0|    0.8|    1|     0|  0.149|0.19325742574257426|\n",
      "| 62|  0|   null|    null|  4|     140|  0|   0|   0|  0|       0|    6.0|    160|    0|    3.6|    3|     1|  0.149|              0.149|\n",
      "| 57|  0|   null|    null|  4|     120|  0|   0|   0|  0|       0|    9.0|    163|    1|    0.6|    1|     0|  0.149|              0.149|\n",
      "| 63|  1|   null|    null|  4|     130|  0|   1|   1|  0|       0|    8.0|    147|    0|    1.4|    2|     1|  0.149|0.19325742574257426|\n",
      "| 53|  1|   null|    null|  4|     140|  1|   1|   0|  0|       1|    5.5|    155|    1|    3.1|    3|     1|  0.138|0.19325742574257426|\n",
      "| 57|  1|   null|    null|  4|     140|  0|   0|   0|  0|       0|    8.2|    148|    0|    0.4|    2|     0|  0.149|0.19325742574257426|\n",
      "| 56|  0|   null|    null|  2|     140|  0|   1|   1|  0|       0|    4.5|    153|    0|    1.3|    2|     0|  0.149|              0.149|\n",
      "| 56|  1|   null|    null|  3|     130|  1|   0|   0|  0|       0|   13.0|    142|    1|    0.6|    2|     1|  0.149|0.19325742574257426|\n",
      "| 44|  1|   null|    null|  2|     120|  0|   1|   0|  0|       0|    9.3|    173|    0|    0.0|    1|     0|  0.109|0.16342574257425743|\n",
      "| 52|  1|   null|    null|  3|     172|  1|   0|   0|  0|       0|   12.5|    162|    0|    0.5|    1|     0|  0.138|0.19325742574257426|\n",
      "| 57|  1|   null|    null|  3|     150|  0|   0|   1|  0|       0|   11.0|    174|    0|    1.6|    1|     0|  0.149|0.19325742574257426|\n",
      "| 48|  1|   null|    null|  2|     110|  0|   1|   0|  0|       0|    9.8|    168|    0|    1.0|    3|     1|  0.138|0.19325742574257426|\n",
      "| 54|  1|   null|    null|  4|     140|  0|   0|   0|  0|       1|    7.8|    160|    0|    1.2|    1|     0|  0.138|0.19325742574257426|\n",
      "| 48|  0|   null|    null|  3|     130|  0|   0|   0|  0|       0|   10.0|    139|    0|    0.2|    1|     0|  0.138|              0.149|\n",
      "| 49|  1|   null|    null|  2|     130|  0|   0|   0|  0|       0|   12.0|    171|    0|    0.6|    1|     0|  0.138|0.19325742574257426|\n",
      "+---+---+-------+--------+---+--------+---+----+----+---+--------+-------+-------+-----+-------+-----+------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', 'exang', 'oldpeak', 'slope', 'target', 'smoke_1', 'smoke_2']\n",
      "[]\n",
      "Error initializing Imputer: __provides__\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Predict Heart Disease\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    raw_data = read_data(spark)\n",
    "    data = clean_data(raw_data)\n",
    "    data.show()\n",
    "    pipeline(data)\n",
    "    \n",
    "    # data.show()\n",
    "\n",
    "\n",
    "    spark.stop()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c08257-985e-4e91-9402-84f1c603a19e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ef127-ab45-4266-989d-3b767f22583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id='',\n",
    "                  aws_secret_access_key='',\n",
    "                  aws_session_token='')\n",
    "\n",
    "\n",
    "bucket_name = 'de300spring2024'\n",
    "object_key = 'emily_kohlberg/hw/heart_disease.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ede6f-9c79-4732-b2b3-02187802c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee58c7b-d178-4d1a-9404-53f63ad3d5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(BytesIO(csv_string.encode()))\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8437dc-a484-4e3c-9325-fc6e97d76487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get data from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7aff3c-c4c5-4f70-a8cc-906d79c091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    read data; since the data has the header we let spark guess the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    data = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(os.path.join(DATA_FOLDER,\"*.csv\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc3cc5-fc10-49c1-ac72-3b45c4798c04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613c02b-84f6-4e60-b556-6b8146af89c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Clean and Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaab5a38-1e58-404e-aa5c-2803604c4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_cols(data: DataFrame) -> DataFrame:\n",
    "    columns_to_retain = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'smoke', \n",
    "                         'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                         'exang', 'oldpeak', 'slope', 'target']\n",
    "    \n",
    "    filtered_data = data.select(columns_to_retain)\n",
    "    return filtered_data\n",
    "    \n",
    "def replace_out_of_range(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('painloc', when(col('painloc') < 0, 0).when(col('painloc') > 1, 1).otherwise(col('painloc')))\n",
    "    data = data.withColumn('painexer', when(col('painexer') < 0, 0).when(col('painexer') > 1, 1).otherwise(col('painexer')))\n",
    "    data = data.withColumn('trestbps', when(col('trestbps') < 100, 100).otherwise(col('trestbps')))\n",
    "    data = data.withColumn('oldpeak', when(col('oldpeak') < 0, 0).when(col('oldpeak') > 4, 4).otherwise(col('oldpeak')))\n",
    "    data = data.withColumn('fbs', when(col('fbs') < 0, 0).when(col('fbs') > 1, 1).otherwise(col('fbs')))\n",
    "    data = data.withColumn('prop', when(col('prop') < 0, 0).when(col('prop') > 1, 1).otherwise(col('prop')))\n",
    "    data = data.withColumn('nitr', when(col('nitr') < 0, 0).when(col('nitr') > 1, 1).otherwise(col('nitr')))\n",
    "    data = data.withColumn('pro', when(col('pro') < 0, 0).when(col('pro') > 1, 1).otherwise(col('pro')))\n",
    "    data = data.withColumn('diuretic', when(col('diuretic') < 0, 0).when(col('diuretic') > 1, 1).otherwise(col('diuretic')))\n",
    "    data = data.withColumn('exang', when(col('exang') < 0, 0).when(col('exang') > 1, 1).otherwise(col('exang')))\n",
    "    data = data.withColumn('slope', when(col('slope') < 1, None).when(col('slope') > 3, None).otherwise(col('slope')))\n",
    "    return data\n",
    "    \n",
    "def replace_nulls_with_mean(data: DataFrame) -> DataFrame:\n",
    "    columns_for_imputation = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', \n",
    "                     'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                     'exang', 'oldpeak', 'slope', 'target']\n",
    "    \n",
    "    for column in columns_for_imputation:\n",
    "        mean_value = data.select(F.mean(col(column))).collect()[0][0]\n",
    "        if mean_value is not None:\n",
    "            data = data.withColumn(column, when(col(column).isNull(), mean_value).otherwise(col(column)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2876ad52-7dd2-41a8-a252-8b7f778f07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoke_1(data: DataFrame) -> DataFrame:\n",
    "    url1 = 'https://www.abs.gov.au/statistics/health/health-conditions-and-risks/smoking-and-vaping/latest-release'\n",
    "    response = requests.get(url1)\n",
    "        \n",
    "    # get the HTML file as a string\n",
    "    html_content = response.content\n",
    "    \n",
    "    # create a selector object\n",
    "    full_sel = Selector(text=html_content)\n",
    "    \n",
    "    # select all tables in page -> returns a SelectorList object\n",
    "    tables = full_sel.xpath('//table')\n",
    "    smokers_by_age = tables[1]\n",
    "    # get the rows\n",
    "    rows = smokers_by_age.xpath('./tbody//tr')\n",
    "\n",
    "    def parse_row_1(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('.//th | .//td')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            if i == 0 or i == 10:\n",
    "                cell_text = cell.xpath('normalize-space(.)').get()\n",
    "                cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "                # if there are br tags, there will be some binary characters\n",
    "                cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "                row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "    \n",
    "    table_data = [parse_row_1(row) for row in rows]\n",
    "\n",
    "    def get_rate_1(age):\n",
    "        try:\n",
    "            age = int(age)\n",
    "            for i, row in enumerate(table_data):\n",
    "                if i < len(table_data) - 1:\n",
    "                    cutoff = row[0].split('–')[1]\n",
    "                    if age <= int(cutoff):\n",
    "                        return float(row[1])\n",
    "                else:\n",
    "                    return float(row[1])\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Register the UDF\n",
    "    get_rate_1_udf = F.udf(lambda age: get_rate_1(age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_1', when(col('smoke_1').isNull(), get_rate_1_udf(col('age'))).otherwise(col('smoke_1')))\n",
    "\n",
    "    return data\n",
    "\n",
    "def smoke_2(data: DataFrame) -> DataFrame:\n",
    "    url2 = 'https://www.cdc.gov/tobacco/data_statistics/fact_sheets/adult_data/cig_smoking/index.htm'\n",
    "    response = requests.get(url2)\n",
    "\n",
    "    # Create a scrapy Selector from the response content\n",
    "    selector = Selector(text=response.content)\n",
    "\n",
    "    ul_sel_list = selector.xpath('//ul[@class=\"block-list\"]')\n",
    "    genders = ul_sel_list[0]\n",
    "    ages = ul_sel_list[1]\n",
    "\n",
    "    def clean_gender_percents(rows):\n",
    "        dict = {}\n",
    "        for row in rows:\n",
    "            gender = 'woman' if 'women' in row.split('(')[0] else 'man'\n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            dict[gender] = float(percent)\n",
    "        return dict\n",
    "\n",
    "    def clean_age_percents(rows):\n",
    "        for i, row in enumerate(rows):\n",
    "            if i < len(rows) - 1:\n",
    "                age = int(row.split('–')[1].split(' ')[0])\n",
    "            else:\n",
    "                age = int(row.split(' ')[7])\n",
    "                \n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            rows[i] = [age, percent]\n",
    "        return rows\n",
    "\n",
    "    def parse_row_2(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('./li')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            cell_text = cell.xpath('normalize-space(.)').get()\n",
    "            cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "            # if there are br tags, there will be some binary characters\n",
    "            cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "            row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "\n",
    "    per_by_gender = clean_gender_percents(parse_row_2(genders))\n",
    "    per_by_age = clean_age_percents(parse_row_2(ages))\n",
    "\n",
    "    def get_rate_2(sex, age):\n",
    "        if sex == 0:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1]\n",
    "                    else:\n",
    "                        return row[1]\n",
    "            except:\n",
    "                return np.nan\n",
    "        else:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "                    else:\n",
    "                        return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "    # Register the UDF\n",
    "    get_rate_2_udf = F.udf(lambda sex, age: get_rate_2(sex, age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_2', when(col('smoke_2').isNull(), get_rate_2_udf(col('sex'), col('age'))).otherwise(col('smoke_2')))\n",
    "\n",
    "    return data \n",
    "\n",
    "def impute_smoke(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('smoke_1', F.col('smoke'))\n",
    "    data = data.withColumn('smoke_2', F.col('smoke'))\n",
    "\n",
    "    data = smoke_1(data)\n",
    "    data = smoke_2(data)\n",
    "\n",
    "    data = data.drop('smoke')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c3db1-7e68-4f9a-84ba-1504017673af",
   "metadata": {},
   "source": [
    "### Final Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650095cd-48a6-4fd4-9f74-5d01e35f9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: DataFrame) -> DataFrame:\n",
    "    data = retain_cols(data)\n",
    "    data = replace_out_of_range(data)\n",
    "    # data = replace_nulls_with_mean(data)\n",
    "    data = impute_smoke(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d54632-f481-4f72-bc1d-c9a66a1fb582",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83af3760-edd2-4965-b655-34539851c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data: DataFrame):\n",
    "\n",
    "    data = data.withColumn(\"age\", data[\"age\"].cast(IntegerType()))\n",
    "\n",
    "    numeric_features = [f.name for f in data.schema.fields if isinstance(f.dataType, DoubleType) or isinstance(f.dataType, FloatType) or isinstance(f.dataType, IntegerType) or isinstance(f.dataType, LongType)]\n",
    "    string_features = [f.name for f in data.schema.fields if isinstance(f.dataType, StringType)]\n",
    "\n",
    "    print(numeric_features)\n",
    "    print(string_features)\n",
    "\n",
    "    features = [f.name for f in data.schema.fields]\n",
    "\n",
    "    imputed_columns = [f\"Imputed{v}\" for v in features]\n",
    "    \n",
    "\n",
    "    try:\n",
    "        imputer = Imputer(inputCols=features, outputCols=imputed_columns, strategy=\"mean\")\n",
    "        print(\"Imputer initialized successfully.\")\n",
    "    except AttributeError as e:\n",
    "        print(\"Error initializing Imputer:\", e)\n",
    "        return\n",
    "    # imputer = Imputer(inputCols=features, outputCols=imputed_columns, strategy=\"mean\")\n",
    "\n",
    "\n",
    "    # Assemble feature columns into a single feature vector\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=imputed_columns, \n",
    "        outputCol=\"features\"\n",
    "        )\n",
    "\n",
    "    # Define a Random Forest classifier\n",
    "    classifier = RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\")\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(stages=[imputer, assembler, classifier])\n",
    "    \n",
    "    # Set up the parameter grid for maximum tree depth\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(classifier.maxDepth, [2, 4, 6, 8, 10]) \\\n",
    "        .addGrid(classifier.numTrees, [150, 200, 250, 500]) \\\n",
    "        .build()\n",
    "\n",
    "    # Set up the cross-validator\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=NUMBER_OF_FOLDS,\n",
    "        seed=SPLIT_SEED)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = data.randomSplit([TRAIN_TEST_SPLIT, 1-TRAIN_TEST_SPLIT], seed=SPLIT_SEED)\n",
    "\n",
    "    # Train the cross-validated pipeline model\n",
    "    cvModel = crossval.fit(train_data)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = cvModel.transform(test_data)\n",
    "\n",
    "    # Evaluate the model\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    print(f\"Area Under ROC Curve: {auc:.4f}\")\n",
    "\n",
    "    # Get the best RandomForest model\n",
    "    best_model = cvModel.bestModel.stages[-1]\n",
    "\n",
    "    # Retrieve the selected maximum tree depth\n",
    "    selected_max_depth = best_model.getOrDefault(best_model.getParam(\"maxDepth\"))\n",
    "\n",
    "    # Print the selected maximum tree depth\n",
    "    print(f\"Selected Maximum Tree Depth: {selected_max_depth}\")\n",
    "\n",
    "    # Retrieve the selected number of trees\n",
    "    selected_num_trees = best_model.getOrDefault(best_model.getParam(\"numTrees\"))\n",
    "\n",
    "    # Print the selected number of trees\n",
    "    print(f\"Selected Number of Trees: {selected_num_trees}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
