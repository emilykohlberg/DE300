{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2336782c-4ac0-483d-bb5d-672220c6035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import psycopg2\n",
    "\n",
    "#required for navigating machine's directory\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c08257-985e-4e91-9402-84f1c603a19e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207ef127-ab45-4266-989d-3b767f22583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id='ASIAYAAO5HRMCTGD2S34',\n",
    "                  aws_secret_access_key='ztnA1G3cMmvgV3r/jhsgTqLbZi0CFfZ/YqPbWLp1',\n",
    "                  aws_session_token='IQoJb3JpZ2luX2VjEIT//////////wEaCXVzLWVhc3QtMiJGMEQCIHgTkuFM5YmWKEE5gCfg638b6kdEJ3CS0UwB9i5p3hW5AiAMvGXT0tlLw6s7QThV6iXvH1eEFHjLUMOUrIzvtFoJJyr0Agjd//////////8BEAAaDDU0OTc4NzA5MDAwOCIM2TeVXefESlmSulntKsgC9XXRNdKaJcmZ2scit7L7xT3SvT9mEiMzvSg85cowwl4WKtSUfBIMfV7iLU9VThzFALnVubXCJoXUOLa0ZCAjJ7COZmoeEjUEZC7zIXKkdslzGt2W5hPoZmt9ytGwtvKGCyNmjESrAPOcEoe6ilIfGRXHRt224FdLTBMImJKn6IPRivVASJ4zerNbhTM9O5YcDfJD9h0YUhrtpbVoDmEi4u9J1z2a72VgmbTpIeysNiVWg5rJnQDgiWU4dq8amFiCMpbYZ1lQG1okSL10P/fodJ0FWMp1Olz0A7IN7vMMQf7FVwSRiqmQ73kcyjDCGawJtDjKj/IA023o537wXgf0v//e2suw8BBCpYPdYfnpN+5co6eyGnMBjPSGuQCv6frh+pN2Bdq6Cnxr2DslmdBApx7pFzO5kVu6/kj6K1+9hS4KlCsStIIpIjCAi+qxBjqoAU/uf849jivIbZB6i9R9QmAMOV5XHSjJYoRCmD5VA3+1OlPZIZVFyxZ4nvvW2344Sbh3lTB38fiUkgIb9SJJ+kguWZGMP3j9KHjY4wAZiEjWf8KTJPXgIkE15xbWNZftBkHnxeozaOisrRrsJd1+oAqKTBrvS533dGJVmK3doK3z8zrdpEGrQdTcdQhPm+UG2SfjaxmTwXXvrxi/mGNnYSvhdaR0mipNrw==')\n",
    "\n",
    "\n",
    "bucket_name = 'de300spring2024'\n",
    "object_key = 'emily_kohlberg/hw/heart_disease.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7ede6f-9c79-4732-b2b3-02187802c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee58c7b-d178-4d1a-9404-53f63ad3d5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>htn</th>\n",
       "      <th>chol</th>\n",
       "      <th>...</th>\n",
       "      <th>exeref</th>\n",
       "      <th>exerwm</th>\n",
       "      <th>thal</th>\n",
       "      <th>thalsev</th>\n",
       "      <th>thalpul</th>\n",
       "      <th>earlobe</th>\n",
       "      <th>cmo</th>\n",
       "      <th>cday</th>\n",
       "      <th>cyr</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1 888 -9 4016 8216 8216 788 0 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>-0 0 0 1 9 -9 130 80 0 130 80 0 11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>-9 3 1h9 1 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>-9 3 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>-9 -9 -9 3 -9 -4 1 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         age  sex  painloc  painexer  relrest  \\\n",
       "0                                         63  1.0      NaN       NaN      NaN   \n",
       "1                                         67  1.0      NaN       NaN      NaN   \n",
       "2                                         67  1.0      NaN       NaN      NaN   \n",
       "3                                         37  1.0      NaN       NaN      NaN   \n",
       "4                                         41  0.0      NaN       NaN      NaN   \n",
       "...                                      ...  ...      ...       ...      ...   \n",
       "1056  1 888 -9 4016 8216 8216 788 0 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1057      -0 0 0 1 9 -9 130 80 0 130 80 0 11  NaN      NaN       NaN      NaN   \n",
       "1058                     -9 3 1h9 1 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1059                           -9 3 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1060                    -9 -9 -9 3 -9 -4 1 1  NaN      NaN       NaN      NaN   \n",
       "\n",
       "      pncaden   cp  trestbps  htn   chol  ...  exeref  exerwm  thal  thalsev  \\\n",
       "0         NaN  1.0     145.0  1.0  233.0  ...     NaN     NaN   6.0      NaN   \n",
       "1         NaN  4.0     160.0  1.0  286.0  ...     NaN     NaN   3.0      NaN   \n",
       "2         NaN  4.0     120.0  1.0  229.0  ...     NaN     NaN   7.0      NaN   \n",
       "3         NaN  3.0     130.0  0.0  250.0  ...     NaN     NaN   3.0      NaN   \n",
       "4         NaN  2.0     130.0  1.0  204.0  ...     NaN     NaN   3.0      NaN   \n",
       "...       ...  ...       ...  ...    ...  ...     ...     ...   ...      ...   \n",
       "1056      NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1057      NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1058      NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1059      NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1060      NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "\n",
       "      thalpul  earlobe  cmo  cday   cyr  target  \n",
       "0         NaN      NaN  2.0  16.0  81.0     0.0  \n",
       "1         NaN      NaN  2.0   5.0  81.0     1.0  \n",
       "2         NaN      NaN  2.0  20.0  81.0     1.0  \n",
       "3         NaN      NaN  2.0   4.0  81.0     0.0  \n",
       "4         NaN      NaN  2.0  18.0  81.0     0.0  \n",
       "...       ...      ...  ...   ...   ...     ...  \n",
       "1056      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1057      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1058      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1059      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1060      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "\n",
       "[1061 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(BytesIO(csv_string.encode()))\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8437dc-a484-4e3c-9325-fc6e97d76487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get data from rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7420c8f-bd9e-4072-b583-f94fa55bcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string  = \"postgresql://myuser:mypassword@postgres-container/mydatabase\"\n",
    "rawdata_path = \"../rawdata/\"\n",
    "staging_data_dir = '../staging_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7aff3c-c4c5-4f70-a8cc-906d79c091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process: str) -> pd.DataFrame:\n",
    "    with open(file_to_process, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "\n",
    "    data = pd.read_csv(file_to_process)\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    extracted_data = pd.DataFrame(columns = header)\n",
    "    extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867c3360-c8cc-4053-a76a-2f79d41e5cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67/3615485252.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>htn</th>\n",
       "      <th>chol</th>\n",
       "      <th>...</th>\n",
       "      <th>exeref</th>\n",
       "      <th>exerwm</th>\n",
       "      <th>thal</th>\n",
       "      <th>thalsev</th>\n",
       "      <th>thalpul</th>\n",
       "      <th>earlobe</th>\n",
       "      <th>cmo</th>\n",
       "      <th>cday</th>\n",
       "      <th>cyr</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1 888 -9 4016 8216 8216 788 0 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>-0 0 0 1 9 -9 130 80 0 130 80 0 11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>-9 3 1h9 1 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>-9 3 -9 -9 -9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>-9 -9 -9 3 -9 -4 1 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         age  sex  painloc  painexer  relrest  \\\n",
       "0                                         63  1.0      NaN       NaN      NaN   \n",
       "1                                         67  1.0      NaN       NaN      NaN   \n",
       "2                                         67  1.0      NaN       NaN      NaN   \n",
       "3                                         37  1.0      NaN       NaN      NaN   \n",
       "4                                         41  0.0      NaN       NaN      NaN   \n",
       "...                                      ...  ...      ...       ...      ...   \n",
       "1056  1 888 -9 4016 8216 8216 788 0 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1057      -0 0 0 1 9 -9 130 80 0 130 80 0 11  NaN      NaN       NaN      NaN   \n",
       "1058                     -9 3 1h9 1 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1059                           -9 3 -9 -9 -9  NaN      NaN       NaN      NaN   \n",
       "1060                    -9 -9 -9 3 -9 -4 1 1  NaN      NaN       NaN      NaN   \n",
       "\n",
       "     pncaden   cp  trestbps  htn   chol  ...  exeref  exerwm  thal  thalsev  \\\n",
       "0        NaN  1.0     145.0  1.0  233.0  ...     NaN     NaN   6.0      NaN   \n",
       "1        NaN  4.0     160.0  1.0  286.0  ...     NaN     NaN   3.0      NaN   \n",
       "2        NaN  4.0     120.0  1.0  229.0  ...     NaN     NaN   7.0      NaN   \n",
       "3        NaN  3.0     130.0  0.0  250.0  ...     NaN     NaN   3.0      NaN   \n",
       "4        NaN  2.0     130.0  1.0  204.0  ...     NaN     NaN   3.0      NaN   \n",
       "...      ...  ...       ...  ...    ...  ...     ...     ...   ...      ...   \n",
       "1056     NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1057     NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1058     NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1059     NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "1060     NaN  NaN       NaN  NaN    NaN  ...     NaN     NaN   NaN      NaN   \n",
       "\n",
       "      thalpul  earlobe  cmo  cday   cyr  target  \n",
       "0         NaN      NaN  2.0  16.0  81.0     0.0  \n",
       "1         NaN      NaN  2.0   5.0  81.0     1.0  \n",
       "2         NaN      NaN  2.0  20.0  81.0     1.0  \n",
       "3         NaN      NaN  2.0   4.0  81.0     0.0  \n",
       "4         NaN      NaN  2.0  18.0  81.0     0.0  \n",
       "...       ...      ...  ...   ...   ...     ...  \n",
       "1056      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1057      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1058      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1059      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "1060      NaN      NaN  NaN   NaN   NaN     NaN  \n",
       "\n",
       "[1061 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = extract_from_csv(\"../rawdata/heart_disease.csv\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc3cc5-fc10-49c1-ac72-3b45c4798c04",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6f860a0-c88b-46a0-a1ec-a10c5ea63974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>smoke</th>\n",
       "      <th>fbs</th>\n",
       "      <th>prop</th>\n",
       "      <th>nitr</th>\n",
       "      <th>pro</th>\n",
       "      <th>diuretic</th>\n",
       "      <th>thaldur</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  painloc  painexer   cp  trestbps  smoke  fbs  prop  nitr  pro  \\\n",
       "0    63  1.0      NaN       NaN  1.0     145.0    NaN  1.0   0.0   0.0  0.0   \n",
       "1    67  1.0      NaN       NaN  4.0     160.0    NaN  0.0   1.0   0.0  0.0   \n",
       "2    67  1.0      NaN       NaN  4.0     120.0    NaN  0.0   1.0   0.0  0.0   \n",
       "3    37  1.0      NaN       NaN  3.0     130.0    NaN  0.0   1.0   0.0  0.0   \n",
       "4    41  0.0      NaN       NaN  2.0     130.0    NaN  0.0   0.0   0.0  0.0   \n",
       "..   ..  ...      ...       ...  ...       ...    ...  ...   ...   ...  ...   \n",
       "894  54  1.0      1.0       1.0  4.0     180.0    NaN  NaN   0.0   0.0  0.0   \n",
       "895  56  1.0      1.0       1.0  4.0     125.0    1.0  1.0   0.0   0.0  0.0   \n",
       "896  56  1.0      0.0       1.0  3.0     125.0    NaN  NaN   0.0   0.0  0.0   \n",
       "897  54  1.0      1.0       1.0  4.0     130.0    NaN  NaN   0.0   0.0  0.0   \n",
       "898  66  0.0      1.0       1.0  4.0     155.0    NaN  NaN   0.0   0.0  0.0   \n",
       "\n",
       "     diuretic  thaldur  thalach  exang  oldpeak  slope  target  \n",
       "0         0.0     10.5    150.0    0.0      2.3    3.0     0.0  \n",
       "1         0.0      9.5    108.0    1.0      1.5    2.0     1.0  \n",
       "2         0.0      8.5    129.0    1.0      2.6    2.0     1.0  \n",
       "3         0.0     13.0    187.0    0.0      3.5    3.0     0.0  \n",
       "4         0.0      7.0    172.0    0.0      1.4    1.0     0.0  \n",
       "..        ...      ...      ...    ...      ...    ...     ...  \n",
       "894       0.0      7.5    150.0    0.0      1.5    2.0     1.0  \n",
       "895       0.0      6.5    103.0    1.0      1.0    2.0     1.0  \n",
       "896       0.0      6.0     98.0    0.0     -2.0    2.0     1.0  \n",
       "897       0.0      9.5    110.0    1.0      3.0    2.0     1.0  \n",
       "898       0.0      6.5     90.0    0.0      0.0    NaN     1.0  \n",
       "\n",
       "[899 rows x 18 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_retain = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'smoke', \n",
    "                     'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                     'exang', 'oldpeak', 'slope', 'target']\n",
    "\n",
    "data = raw_data[columns_to_retain]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07efa8f6-a565-4ed4-87e1-d5060fc4896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and imputing steps for columns other than `smoke:’\n",
    "# a. painloc, painexer\n",
    "# b. tresbps: Replace values less than 100 mm Hg\n",
    "# c. oldpeak: Replace values less than 0 and those greater than 4\n",
    "# d. thaldur, thalach: Replace the missing values\n",
    "# e. fbs, prop, nitr, pro, diuretic: Replace the missing values and values greater than 1\n",
    "# f. exang, slope: Replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1fa3ae14-309c-47c3-abbe-7fef4e8bda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# painloc, painexer: replace <0 with 0, >1 with 1, and NaN with the mode\n",
    "data.loc[data['painloc'] < 0, 'painloc'] = 0\n",
    "data.loc[data['painloc'] > 1, 'painloc'] = 1\n",
    "mode_painloc = data['painloc'].mode()\n",
    "data.loc[data['painloc'].isna(), 'painloc'] = mode_painloc\n",
    "\n",
    "data.loc[data['painexer'] < 0, 'painexer'] = 0\n",
    "data.loc[data['painexer'] > 1, 'painexer'] = 1\n",
    "mode_painexer = data['painexer'].mode()\n",
    "data.loc[data['painexer'].isna(), 'painexer'] = mode_painexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef6feebc-fec5-4daf-b10f-3279582a6dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tresbps: Replace values less than 100 mm Hg in the 'trestbps' column with 100 and NaN to the mean\n",
    "data.loc[data['trestbps'] < 100, 'trestbps'] = 100\n",
    "mean_trestbps = data['trestbps'].mean()\n",
    "data.loc[data['trestbps'].isna(), 'trestbps'] = mean_trestbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0726e319-aeba-419c-8704-49c4ad6defdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldpeak: Replace values less than 0 with 0 and those greater than 4 with 4 and NaN to the mean\n",
    "data.loc[data['oldpeak'] < 0, 'oldpeak'] = 0\n",
    "data.loc[data['oldpeak'] > 4, 'oldpeak'] = 4\n",
    "mean_oldpeak = data['oldpeak'].mean()\n",
    "data.loc[data['oldpeak'].isna(), 'oldpeak'] = mean_oldpeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9da2aa0-268c-43aa-b5dd-c3ab6f1119d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thaldur, thalach: Replace the missing values with mean\n",
    "mean_thaldur = data['thaldur'].mean()\n",
    "data.loc[data['thaldur'].isna(), 'thaldur'] = mean_thaldur\n",
    "\n",
    "mean_thalach = data['thalach'].mean()\n",
    "data.loc[data['thalach'].isna(), 'thalach'] = mean_thalach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63822f88-fc14-477a-8a7c-2b1df3f8ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbs, prop, nitr, pro, diuretic: replace <0 with 0, >1 with 1, and NaN with the mode\n",
    "data.loc[data['fbs'] < 0, 'fbs'] = 0\n",
    "data.loc[data['fbs'] > 1, 'fbs'] = 1\n",
    "mode_fbs = data['fbs'].mode()\n",
    "data.loc[data['fbs'].isna(), 'fbs'] = mode_fbs\n",
    "\n",
    "data.loc[data['prop'] < 0, 'prop'] = 0\n",
    "data.loc[data['prop'] > 1, 'prop'] = 1\n",
    "mode_prop = data['prop'].mode()\n",
    "data.loc[data['prop'].isna(), 'prop'] = mode_prop\n",
    "\n",
    "data.loc[data['nitr'] < 0, 'nitr'] = 0\n",
    "data.loc[data['nitr'] > 1, 'nitr'] = 1\n",
    "mode_nitr = data['nitr'].mode()\n",
    "data.loc[data['nitr'].isna(), 'nitr'] = mode_nitr\n",
    "\n",
    "data.loc[data['pro'] < 0, 'pro'] = 0\n",
    "data.loc[data['pro'] > 1, 'pro'] = 1\n",
    "mode_pro = data['pro'].mode()\n",
    "data.loc[data['pro'].isna(), 'pro'] = mode_pro\n",
    "\n",
    "data.loc[data['diuretic'] < 0, 'diuretic'] = 0\n",
    "data.loc[data['diuretic'] > 1, 'diuretic'] = 1\n",
    "mode_diuretic = data['diuretic'].mode()\n",
    "data.loc[data['diuretic'].isna(), 'diuretic'] = mode_diuretic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d805c4ef-3177-4f4c-bec4-98373ecef952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exang, slope: Replace the missing values\n",
    "data.loc[data['exang'] < 0, 'exang'] = 0\n",
    "data.loc[data['exang'] > 1, 'exang'] = 1\n",
    "mode_exang = data['exang'].mode()\n",
    "data.loc[data['exang'].isna(), 'exang'] = mode_exang\n",
    "\n",
    "mode_slope = data['slope'].mode()\n",
    "data.loc[data['slope'] < 1, 'slope'] = mode_slope\n",
    "data.loc[data['slope'] > 3, 'slope'] = mode_slope\n",
    "data.loc[data['slope'].isna(), 'slope'] = mode_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d54632-f481-4f72-bc1d-c9a66a1fb582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f9687d-3d81-4980-b964-46bea4587670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction does not work when target is NaN\n",
    "raw_data = raw_data.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f01a36-c6aa-442f-a87b-7d6a2771246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.drop('target', axis=1)\n",
    "y = raw_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539d0240-b9e2-4fc2-8560-414645d96443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1201, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(), model)\n\u001b[1;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid[model_name], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Evaluate performance using cross-validation\u001b[39;00m\n\u001b[1;32m     24\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1201, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'logisticregression__C': [0.1, 1, 10]},\n",
    "    'Decision Tree': {'decisiontreeclassifier__max_depth': [None, 5, 10, 20]},\n",
    "    'Random Forest': {'randomforestclassifier__n_estimators': [100, 200, 300], 'randomforestclassifier__max_depth': [None, 5, 10]},\n",
    "    'Support Vector Machine': {'svc__C': [0.1, 1, 10], 'svc__kernel': ['linear', 'rbf']}\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning and assess performance\n",
    "for model_name, model in models.items():\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "    grid_search = GridSearchCV(pipe, param_grid[model_name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate performance using cross-validation\n",
    "    cv_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Report relevant performance metrics\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Cross-Validation Accuracy:\", np.mean(cv_scores))\n",
    "    print(\"Cross-Validation Precision:\", np.mean(cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='precision')))\n",
    "    print(\"Cross-Validation Recall:\", np.mean(cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='recall')))\n",
    "    print(\"Cross-Validation F1-score:\", np.mean(cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='f1')))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
