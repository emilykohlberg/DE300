{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27e7f5c5-1f5e-4773-8950-66be75241122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, FloatType, LongType, StringType, DoubleType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a5270-37a8-4a0e-9663-2f0c09b88269",
   "metadata": {},
   "source": [
    "## Check Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06b828d-1d7a-41a3-8929-703028401ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/demos/bin/python3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e12fef7f-59b8-4b2b-b7b6-f2fff328616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "\n",
    "NUMBER_OF_FOLDS = 3\n",
    "SPLIT_SEED = 7576\n",
    "TRAIN_TEST_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a794b4a-3efa-48bc-a8c3-2df602c90670",
   "metadata": {},
   "source": [
    "## Function for data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ab6c2d-df8f-4aaf-bdfe-a6f30efaba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    read data; since the data has the header we let spark guess the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV data into a DataFrame\n",
    "    data = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(os.path.join(DATA_FOLDER,\"heart_disease.csv\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10eaf2f-0ddb-4d60-8d5b-d4cdc7c2b15c",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9d2bb52-d0af-4111-b3ee-2173f4101598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_cols(data: DataFrame) -> DataFrame:\n",
    "    columns_to_retain = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'smoke', \n",
    "                         'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                         'exang', 'oldpeak', 'slope', 'target']\n",
    "    \n",
    "    filtered_data = data.select(columns_to_retain)\n",
    "    return filtered_data\n",
    "    \n",
    "def replace_out_of_range(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('painloc', when(col('painloc') < 0, 0).when(col('painloc') > 1, 1).otherwise(col('painloc')))\n",
    "    data = data.withColumn('painexer', when(col('painexer') < 0, 0).when(col('painexer') > 1, 1).otherwise(col('painexer')))\n",
    "    data = data.withColumn('trestbps', when(col('trestbps') < 100, 100).otherwise(col('trestbps')))\n",
    "    data = data.withColumn('oldpeak', when(col('oldpeak') < 0, 0).when(col('oldpeak') > 4, 4).otherwise(col('oldpeak')))\n",
    "    data = data.withColumn('fbs', when(col('fbs') < 0, 0).when(col('fbs') > 1, 1).otherwise(col('fbs')))\n",
    "    data = data.withColumn('prop', when(col('prop') < 0, 0).when(col('prop') > 1, 1).otherwise(col('prop')))\n",
    "    data = data.withColumn('nitr', when(col('nitr') < 0, 0).when(col('nitr') > 1, 1).otherwise(col('nitr')))\n",
    "    data = data.withColumn('pro', when(col('pro') < 0, 0).when(col('pro') > 1, 1).otherwise(col('pro')))\n",
    "    data = data.withColumn('diuretic', when(col('diuretic') < 0, 0).when(col('diuretic') > 1, 1).otherwise(col('diuretic')))\n",
    "    data = data.withColumn('exang', when(col('exang') < 0, 0).when(col('exang') > 1, 1).otherwise(col('exang')))\n",
    "    data = data.withColumn('slope', when(col('slope') < 1, None).when(col('slope') > 3, None).otherwise(col('slope')))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9f66a71-5037-4e28-9e72-71be647390b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoke_1(data: DataFrame) -> DataFrame:\n",
    "    url1 = 'https://www.abs.gov.au/statistics/health/health-conditions-and-risks/smoking-and-vaping/latest-release'\n",
    "    response = requests.get(url1)\n",
    "        \n",
    "    # get the HTML file as a string\n",
    "    html_content = response.content\n",
    "    \n",
    "    # create a selector object\n",
    "    full_sel = Selector(text=html_content)\n",
    "    \n",
    "    # select all tables in page -> returns a SelectorList object\n",
    "    tables = full_sel.xpath('//table')\n",
    "    smokers_by_age = tables[1]\n",
    "    # get the rows\n",
    "    rows = smokers_by_age.xpath('./tbody//tr')\n",
    "\n",
    "    def parse_row_1(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('.//th | .//td')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            if i == 0 or i == 10:\n",
    "                cell_text = cell.xpath('normalize-space(.)').get()\n",
    "                cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "                # if there are br tags, there will be some binary characters\n",
    "                cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "                row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "    \n",
    "    table_data = [parse_row_1(row) for row in rows]\n",
    "\n",
    "    def get_rate_1(age):\n",
    "        try:\n",
    "            age = int(age)\n",
    "            for i, row in enumerate(table_data):\n",
    "                if i < len(table_data) - 1:\n",
    "                    cutoff = row[0].split('–')[1]\n",
    "                    if age <= int(cutoff):\n",
    "                        return float(row[1])\n",
    "                else:\n",
    "                    return float(row[1])\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Register the UDF\n",
    "    get_rate_1_udf = F.udf(lambda age: get_rate_1(age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_1', when(col('smoke_1').isNull(), get_rate_1_udf(col('age'))).otherwise(col('smoke_1')))\n",
    "\n",
    "    return data\n",
    "\n",
    "def smoke_2(data: DataFrame) -> DataFrame:\n",
    "    url2 = 'https://www.cdc.gov/tobacco/data_statistics/fact_sheets/adult_data/cig_smoking/index.htm'\n",
    "    response = requests.get(url2)\n",
    "\n",
    "    # Create a scrapy Selector from the response content\n",
    "    selector = Selector(text=response.content)\n",
    "\n",
    "    ul_sel_list = selector.xpath('//ul[@class=\"block-list\"]')\n",
    "    genders = ul_sel_list[0]\n",
    "    ages = ul_sel_list[1]\n",
    "\n",
    "    def clean_gender_percents(rows):\n",
    "        dict = {}\n",
    "        for row in rows:\n",
    "            gender = 'woman' if 'women' in row.split('(')[0] else 'man'\n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            dict[gender] = float(percent)\n",
    "        return dict\n",
    "\n",
    "    def clean_age_percents(rows):\n",
    "        for i, row in enumerate(rows):\n",
    "            if i < len(rows) - 1:\n",
    "                age = int(row.split('–')[1].split(' ')[0])\n",
    "            else:\n",
    "                age = int(row.split(' ')[7])\n",
    "                \n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            rows[i] = [age, percent]\n",
    "        return rows\n",
    "\n",
    "    def parse_row_2(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('./li')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            cell_text = cell.xpath('normalize-space(.)').get()\n",
    "            cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "            # if there are br tags, there will be some binary characters\n",
    "            cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "            row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "\n",
    "    per_by_gender = clean_gender_percents(parse_row_2(genders))\n",
    "    per_by_age = clean_age_percents(parse_row_2(ages))\n",
    "\n",
    "    def get_rate_2(sex, age):\n",
    "        if sex == 0:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1]\n",
    "                    else:\n",
    "                        return row[1]\n",
    "            except:\n",
    "                return np.nan\n",
    "        else:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "                    else:\n",
    "                        return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "    # Register the UDF\n",
    "    get_rate_2_udf = F.udf(lambda sex, age: get_rate_2(sex, age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_2', when(col('smoke_2').isNull(), get_rate_2_udf(col('sex'), col('age'))).otherwise(col('smoke_2')))\n",
    "\n",
    "    return data \n",
    "\n",
    "def impute_smoke(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('smoke_1', F.col('smoke'))\n",
    "    data = data.withColumn('smoke_2', F.col('smoke'))\n",
    "\n",
    "    data = smoke_1(data)\n",
    "    data = smoke_2(data)\n",
    "\n",
    "    data = data.drop('smoke')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da37d86-c3aa-43c2-a838-7b072140259e",
   "metadata": {},
   "source": [
    "## The ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1d53e22-eb2c-4e85-bf7f-12ec742721a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data: DataFrame):\n",
    "\n",
    "    \"\"\"\n",
    "    every attribute that is numeric is non-categorical; this is questionable\n",
    "    \"\"\"\n",
    "\n",
    "    data = retain_cols(data)\n",
    "    data = replace_out_of_range(data)\n",
    "    data = impute_smoke(data)\n",
    "\n",
    "    # drop null targets\n",
    "    data = data.dropna(subset=['target'])\n",
    "\n",
    "    # make age an int\n",
    "    data = data.withColumn(\"age\", data[\"age\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "    numeric_features = [f.name for f in data.schema.fields if isinstance(f.dataType, (DoubleType, FloatType, IntegerType, LongType))]\n",
    "    string_features = [f.name for f in data.schema.fields if isinstance(f.dataType, StringType)]\n",
    "\n",
    "    print(numeric_features)\n",
    "    print(string_features)\n",
    "\n",
    "    # Fill missing values for string columns with a placeholder before indexing\n",
    "    data = data.fillna({col: 'null' for col in string_features})\n",
    "    \n",
    "    # Index string features\n",
    "    indexed_string_columns = [f\"{v}Index\" for v in string_features]\n",
    "    indexers = [StringIndexer(inputCol=col, outputCol=indexed_col, handleInvalid='keep') for col, indexed_col in zip(string_features, indexed_string_columns)]\n",
    "\n",
    "    # Impute missing values for indexed string columns\n",
    "    imputed_columns_string = [f\"Imputed{v}\" for v in indexed_string_columns]\n",
    "    imputer_string = Imputer(inputCols=indexed_string_columns, outputCols=imputed_columns_string, strategy=\"mode\")\n",
    "\n",
    "    \n",
    "    # numeric columns\n",
    "    imputed_columns_numeric = [f\"Imputed{v}\" for v in numeric_features]\n",
    "    imputer_numeric = Imputer(inputCols=numeric_features, outputCols=imputed_columns_numeric, strategy = \"mean\")\n",
    "\n",
    "\n",
    "    # Assemble feature columns into a single feature vector\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=imputed_columns_numeric + imputed_columns_string, \n",
    "        outputCol=\"features\"\n",
    "        )\n",
    "\n",
    "    # Create a list of pipeline stages\n",
    "    stages = indexers + [imputer_string, imputer_numeric, assembler]\n",
    "    \n",
    "    # Create and fit the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    model = pipeline.fit(data)\n",
    "    \n",
    "    # Transform the data\n",
    "    transformed_data = model.transform(data)\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00f200e4-2378-423b-98be-f9996c4a699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Predict Heart Disease\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    try:\n",
    "        # Read data\n",
    "        data = read_data(spark)\n",
    "        \n",
    "        # Print schema and preview the data\n",
    "        data.printSchema()\n",
    "        data.show(5)\n",
    "\n",
    "        # Apply the pipeline\n",
    "        transformed_data = pipeline(data)\n",
    "        \n",
    "        # Show the transformed data, including the imputed columns\n",
    "        columns_to_show = [col for col in transformed_data.columns if col.startswith(\"Imputed\")]\n",
    "        transformed_data.select(columns_to_show).show(truncate=False)\n",
    "        \n",
    "    finally:\n",
    "        # Stop the Spark session\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "315b3402-ad5f-4e46-a317-e0c3d804963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/26 21:27:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- painloc: integer (nullable = true)\n",
      " |-- painexer: integer (nullable = true)\n",
      " |-- relrest: integer (nullable = true)\n",
      " |-- pncaden: string (nullable = true)\n",
      " |-- cp: integer (nullable = true)\n",
      " |-- trestbps: integer (nullable = true)\n",
      " |-- htn: integer (nullable = true)\n",
      " |-- chol: integer (nullable = true)\n",
      " |-- smoke: integer (nullable = true)\n",
      " |-- cigs: integer (nullable = true)\n",
      " |-- years: integer (nullable = true)\n",
      " |-- fbs: integer (nullable = true)\n",
      " |-- dm: integer (nullable = true)\n",
      " |-- famhist: integer (nullable = true)\n",
      " |-- restecg: integer (nullable = true)\n",
      " |-- ekgmo: integer (nullable = true)\n",
      " |-- ekgday(day: integer (nullable = true)\n",
      " |-- ekgyr: integer (nullable = true)\n",
      " |-- dig: integer (nullable = true)\n",
      " |-- prop: integer (nullable = true)\n",
      " |-- nitr: integer (nullable = true)\n",
      " |-- pro: integer (nullable = true)\n",
      " |-- diuretic: integer (nullable = true)\n",
      " |-- proto: integer (nullable = true)\n",
      " |-- thaldur: double (nullable = true)\n",
      " |-- thaltime: double (nullable = true)\n",
      " |-- met: double (nullable = true)\n",
      " |-- thalach: integer (nullable = true)\n",
      " |-- thalrest: integer (nullable = true)\n",
      " |-- tpeakbps: integer (nullable = true)\n",
      " |-- tpeakbpd: integer (nullable = true)\n",
      " |-- dummy: integer (nullable = true)\n",
      " |-- trestbpd: integer (nullable = true)\n",
      " |-- exang: integer (nullable = true)\n",
      " |-- xhypo: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- slope: integer (nullable = true)\n",
      " |-- rldv5: integer (nullable = true)\n",
      " |-- rldv5e: integer (nullable = true)\n",
      " |-- ca: integer (nullable = true)\n",
      " |-- restckm: string (nullable = true)\n",
      " |-- exerckm: integer (nullable = true)\n",
      " |-- restef: double (nullable = true)\n",
      " |-- restwm: integer (nullable = true)\n",
      " |-- exeref: double (nullable = true)\n",
      " |-- exerwm: integer (nullable = true)\n",
      " |-- thal: integer (nullable = true)\n",
      " |-- thalsev: integer (nullable = true)\n",
      " |-- thalpul: integer (nullable = true)\n",
      " |-- earlobe: integer (nullable = true)\n",
      " |-- cmo: integer (nullable = true)\n",
      " |-- cday: integer (nullable = true)\n",
      " |-- cyr: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n",
      "+---+---+-------+--------+-------+-------+---+--------+---+----+-----+----+-----+---+----+-------+-------+-----+----------+-----+---+----+----+---+--------+-----+-------+--------+----+-------+--------+--------+--------+-----+--------+-----+-----+-------+-----+-----+------+---+-------+-------+------+------+------+------+----+-------+-------+-------+---+----+---+------+\n",
      "|age|sex|painloc|painexer|relrest|pncaden| cp|trestbps|htn|chol|smoke|cigs|years|fbs|  dm|famhist|restecg|ekgmo|ekgday(day|ekgyr|dig|prop|nitr|pro|diuretic|proto|thaldur|thaltime| met|thalach|thalrest|tpeakbps|tpeakbpd|dummy|trestbpd|exang|xhypo|oldpeak|slope|rldv5|rldv5e| ca|restckm|exerckm|restef|restwm|exeref|exerwm|thal|thalsev|thalpul|earlobe|cmo|cday|cyr|target|\n",
      "+---+---+-------+--------+-------+-------+---+--------+---+----+-----+----+-----+---+----+-------+-------+-----+----------+-----+---+----+----+---+--------+-----+-------+--------+----+-------+--------+--------+--------+-----+--------+-----+-----+-------+-----+-----+------+---+-------+-------+------+------+------+------+----+-------+-------+-------+---+----+---+------+\n",
      "| 63|  1|   null|    null|   null|   null|  1|     145|  1| 233| null|  50|   20|  1|null|      1|      2|    2|         3|   81|  0|   0|   0|  0|       0|    1|   10.5|     6.0|13.0|    150|      60|     190|      90|  145|      85|    0|    0|    2.3|    3| null|   172|  0|   null|   null|  null|  null|  null|  null|   6|   null|   null|   null|  2|  16| 81|     0|\n",
      "| 67|  1|   null|    null|   null|   null|  4|     160|  1| 286| null|  40|   40|  0|null|      1|      2|    3|         5|   81|  0|   1|   0|  0|       0|    1|    9.5|     6.0|13.0|    108|      64|     160|      90|  160|      90|    1|    0|    1.5|    2| null|   185|  3|   null|   null|  null|  null|  null|  null|   3|   null|   null|   null|  2|   5| 81|     1|\n",
      "| 67|  1|   null|    null|   null|   null|  4|     120|  1| 229| null|  20|   35|  0|null|      1|      2|    2|        19|   81|  0|   1|   0|  0|       0|    1|    8.5|     6.0|10.0|    129|      78|     140|      80|  120|      80|    1|    0|    2.6|    2| null|   150|  2|   null|   null|  null|  null|  null|  null|   7|   null|   null|   null|  2|  20| 81|     1|\n",
      "| 37|  1|   null|    null|   null|   null|  3|     130|  0| 250| null|   0|    0|  0|null|      1|      0|    2|        13|   81|  0|   1|   0|  0|       0|    1|   13.0|    13.0|17.0|    187|      84|     195|      68|  130|      78|    0|    0|    3.5|    3| null|   167|  0|   null|   null|  null|  null|  null|  null|   3|   null|   null|   null|  2|   4| 81|     0|\n",
      "| 41|  0|   null|    null|   null|   null|  2|     130|  1| 204| null|   0|    0|  0|null|      1|      2|    2|         7|   81|  0|   0|   0|  0|       0|    1|    7.0|    null| 9.0|    172|      71|     160|      74|  130|      86|    0|    0|    1.4|    1| null|    40|  0|   null|   null|  null|  null|  null|  null|   3|   null|   null|   null|  2|  18| 81|     0|\n",
      "+---+---+-------+--------+-------+-------+---+--------+---+----+-----+----+-----+---+----+-------+-------+-----+----------+-----+---+----+----+---+--------+-----+-------+--------+----+-------+--------+--------+--------+-----+--------+-----+-----+-------+-----+-----+------+---+-------+-------+------+------+------+------+----+-------+-------+-------+---+----+---+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', 'exang', 'oldpeak', 'slope', 'target', 'smoke_1', 'smoke_2']\n",
      "[]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__provides__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 16\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m data\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Apply the pipeline\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Show the transformed data, including the imputed columns\u001b[39;00m\n\u001b[1;32m     19\u001b[0m columns_to_show \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m transformed_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImputed\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[33], line 33\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Impute missing values for indexed string columns\u001b[39;00m\n\u001b[1;32m     32\u001b[0m imputed_columns_string \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImputed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m indexed_string_columns]\n\u001b[0;32m---> 33\u001b[0m imputer_string \u001b[38;5;241m=\u001b[39m \u001b[43mImputer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputCols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexed_string_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputCols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimputed_columns_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# numeric columns\u001b[39;00m\n\u001b[1;32m     37\u001b[0m imputed_columns_numeric \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImputed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m numeric_features]\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m forces keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/feature.py:2120\u001b[0m, in \u001b[0;36mImputer.__init__\u001b[0;34m(self, strategy, missingValue, inputCols, outputCols, inputCol, outputCol, relativeError)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;129m@keyword_only\u001b[39m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   2106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     relativeError: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   2115\u001b[0m ):\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;124;03m    __init__(self, \\\\*, strategy=\"mean\", missingValue=float(\"nan\"), inputCols=None, \\\u001b[39;00m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;124;03m             outputCols=None, inputCol=None, outputCol=None, relativeError=0.001):\u001b[39;00m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImputer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_java_obj(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.ml.feature.Imputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muid)\n\u001b[1;32m   2122\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/wrapper.py:49\u001b[0m, in \u001b[0;36mJavaWrapper.__init__\u001b[0;34m(self, java_obj)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, java_obj: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mJavaWrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m java_obj\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/feature.py:1943\u001b[0m, in \u001b[0;36m_ImputerParams.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any):\n\u001b[0;32m-> 1943\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ImputerParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDefault(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, missingValue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m), relativeError\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/shared.py:197\u001b[0m, in \u001b[0;36mHasInputCol.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHasInputCol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/shared.py:219\u001b[0m, in \u001b[0;36mHasInputCols.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHasInputCols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/shared.py:241\u001b[0m, in \u001b[0;36mHasOutputCol.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHasOutputCol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDefault(outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muid \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/shared.py:264\u001b[0m, in \u001b[0;36mHasOutputCols.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHasOutputCols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/shared.py:376\u001b[0m, in \u001b[0;36mHasRelativeError.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHasRelativeError\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDefault(relativeError\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/__init__.py:269\u001b[0m, in \u001b[0;36mParams.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params: Optional[List[Param]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Copy the params from the class to the object\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/__init__.py:276\u001b[0m, in \u001b[0;36mParams._copy_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03mCopy all params defined on the class to current object.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 276\u001b[0m src_name_attrs \u001b[38;5;241m=\u001b[39m [(x, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mcls\u001b[39m)]\n\u001b[1;32m    277\u001b[0m src_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m nameAttr: \u001b[38;5;28misinstance\u001b[39m(nameAttr[\u001b[38;5;241m1\u001b[39m], Param), src_name_attrs))\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m src_params:\n",
      "File \u001b[0;32m/tmp/demos/lib/python3.10/site-packages/pyspark/ml/param/__init__.py:276\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03mCopy all params defined on the class to current object.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 276\u001b[0m src_name_attrs \u001b[38;5;241m=\u001b[39m [(x, \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mcls\u001b[39m)]\n\u001b[1;32m    277\u001b[0m src_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m nameAttr: \u001b[38;5;28misinstance\u001b[39m(nameAttr[\u001b[38;5;241m1\u001b[39m], Param), src_name_attrs))\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m src_params:\n",
      "\u001b[0;31mAttributeError\u001b[0m: __provides__"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ba500-308a-454f-be09-03e495ad9a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
