{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2336782c-4ac0-483d-bb5d-672220c6035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import IntegerType, FloatType, LongType, StringType, DoubleType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, GBTClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, Evaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when, col\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eac28b-5d93-4a3a-b30b-3afc5dda624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "\n",
    "NUMBER_OF_FOLDS = 3\n",
    "SPLIT_SEED = 7576\n",
    "TRAIN_TEST_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a54f36-628a-47da-b1d5-864ff840c2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/demos/bin/python3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c08257-985e-4e91-9402-84f1c603a19e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ef127-ab45-4266-989d-3b767f22583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id='',\n",
    "                  aws_secret_access_key='',\n",
    "                  aws_session_token='')\n",
    "\n",
    "\n",
    "bucket_name = 'de300spring2024'\n",
    "object_key = 'emily_kohlberg/hw/heart_disease.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ede6f-9c79-4732-b2b3-02187802c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee58c7b-d178-4d1a-9404-53f63ad3d5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(BytesIO(csv_string.encode()))\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8437dc-a484-4e3c-9325-fc6e97d76487",
   "metadata": {},
   "source": [
    "## Get data from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7aff3c-c4c5-4f70-a8cc-906d79c091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    read data; since the data has the header we let spark guess the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    data = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(os.path.join(DATA_FOLDER,\"heart_disease.csv\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc3cc5-fc10-49c1-ac72-3b45c4798c04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaab5a38-1e58-404e-aa5c-2803604c4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_cols(data: DataFrame) -> DataFrame:\n",
    "    columns_to_retain = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'smoke', \n",
    "                         'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                         'exang', 'oldpeak', 'slope', 'target']\n",
    "    \n",
    "    filtered_data = data.select(columns_to_retain)\n",
    "    return filtered_data\n",
    "    \n",
    "def replace_out_of_range(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('painloc', when(col('painloc') < 0, 0).when(col('painloc') > 1, 1).otherwise(col('painloc')))\n",
    "    data = data.withColumn('painexer', when(col('painexer') < 0, 0).when(col('painexer') > 1, 1).otherwise(col('painexer')))\n",
    "    data = data.withColumn('trestbps', when(col('trestbps') < 100, 100).otherwise(col('trestbps')))\n",
    "    data = data.withColumn('oldpeak', when(col('oldpeak') < 0, 0).when(col('oldpeak') > 4, 4).otherwise(col('oldpeak')))\n",
    "    data = data.withColumn('fbs', when(col('fbs') < 0, 0).when(col('fbs') > 1, 1).otherwise(col('fbs')))\n",
    "    data = data.withColumn('prop', when(col('prop') < 0, 0).when(col('prop') > 1, 1).otherwise(col('prop')))\n",
    "    data = data.withColumn('nitr', when(col('nitr') < 0, 0).when(col('nitr') > 1, 1).otherwise(col('nitr')))\n",
    "    data = data.withColumn('pro', when(col('pro') < 0, 0).when(col('pro') > 1, 1).otherwise(col('pro')))\n",
    "    data = data.withColumn('diuretic', when(col('diuretic') < 0, 0).when(col('diuretic') > 1, 1).otherwise(col('diuretic')))\n",
    "    data = data.withColumn('exang', when(col('exang') < 0, 0).when(col('exang') > 1, 1).otherwise(col('exang')))\n",
    "    data = data.withColumn('slope', when(col('slope') < 1, None).when(col('slope') > 3, None).otherwise(col('slope')))\n",
    "    return data\n",
    "    \n",
    "def replace_nulls_with_mean(data: DataFrame) -> DataFrame:\n",
    "    columns_for_imputation = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', \n",
    "                     'fbs', 'prop', 'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', \n",
    "                     'exang', 'oldpeak', 'slope', 'target']\n",
    "    \n",
    "    for column in columns_for_imputation:\n",
    "        mean_value = data.select(F.mean(col(column))).collect()[0][0]\n",
    "        if mean_value is not None:\n",
    "            data = data.withColumn(column, when(col(column).isNull(), mean_value).otherwise(col(column)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876ad52-7dd2-41a8-a252-8b7f778f07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoke_1(data: DataFrame) -> DataFrame:\n",
    "    url1 = 'https://www.abs.gov.au/statistics/health/health-conditions-and-risks/smoking-and-vaping/latest-release'\n",
    "    response = requests.get(url1)\n",
    "        \n",
    "    # get the HTML file as a string\n",
    "    html_content = response.content\n",
    "    \n",
    "    # create a selector object\n",
    "    full_sel = Selector(text=html_content)\n",
    "    \n",
    "    # select all tables in page -> returns a SelectorList object\n",
    "    tables = full_sel.xpath('//table')\n",
    "    smokers_by_age = tables[1]\n",
    "    # get the rows\n",
    "    rows = smokers_by_age.xpath('./tbody//tr')\n",
    "\n",
    "    def parse_row_1(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('.//th | .//td')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            if i == 0 or i == 10:\n",
    "                cell_text = cell.xpath('normalize-space(.)').get()\n",
    "                cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "                # if there are br tags, there will be some binary characters\n",
    "                cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "                row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "    \n",
    "    table_data = [parse_row_1(row) for row in rows]\n",
    "\n",
    "    def get_rate_1(age):\n",
    "        try:\n",
    "            age = int(age)\n",
    "            for i, row in enumerate(table_data):\n",
    "                if i < len(table_data) - 1:\n",
    "                    cutoff = row[0].split('–')[1]\n",
    "                    if age <= int(cutoff):\n",
    "                        return float(row[1])\n",
    "                else:\n",
    "                    return float(row[1])\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Register the UDF\n",
    "    get_rate_1_udf = F.udf(lambda age: get_rate_1(age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_1', when(col('smoke_1').isNull(), get_rate_1_udf(col('age'))).otherwise(col('smoke_1')))\n",
    "\n",
    "    return data\n",
    "\n",
    "def smoke_2(data: DataFrame) -> DataFrame:\n",
    "    url2 = 'https://www.cdc.gov/tobacco/data_statistics/fact_sheets/adult_data/cig_smoking/index.htm'\n",
    "    response = requests.get(url2)\n",
    "\n",
    "    # Create a scrapy Selector from the response content\n",
    "    selector = Selector(text=response.content)\n",
    "\n",
    "    ul_sel_list = selector.xpath('//ul[@class=\"block-list\"]')\n",
    "    genders = ul_sel_list[0]\n",
    "    ages = ul_sel_list[1]\n",
    "\n",
    "    def clean_gender_percents(rows):\n",
    "        dict = {}\n",
    "        for row in rows:\n",
    "            gender = 'woman' if 'women' in row.split('(')[0] else 'man'\n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            dict[gender] = float(percent)\n",
    "        return dict\n",
    "\n",
    "    def clean_age_percents(rows):\n",
    "        for i, row in enumerate(rows):\n",
    "            if i < len(rows) - 1:\n",
    "                age = int(row.split('–')[1].split(' ')[0])\n",
    "            else:\n",
    "                age = int(row.split(' ')[7])\n",
    "                \n",
    "            percent = float(row.split('(')[1].split('%')[0])\n",
    "            rows[i] = [age, percent]\n",
    "        return rows\n",
    "\n",
    "    def parse_row_2(row:Selector) -> List[str]:\n",
    "        '''\n",
    "        Parses a html row into a list of individual elements\n",
    "        '''\n",
    "        cells = row.xpath('./li')\n",
    "        row_data = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            cell_text = cell.xpath('normalize-space(.)').get()\n",
    "            cell_text = re.sub(r'<.*?>', ' ', cell_text)  # Remove remaining HTML tags\n",
    "            # if there are br tags, there will be some binary characters\n",
    "            cell_text = cell_text.replace('\\xa0', '')  # Remove \\xa0 characters\n",
    "            row_data.append(cell_text)\n",
    "        \n",
    "        return row_data\n",
    "\n",
    "    per_by_gender = clean_gender_percents(parse_row_2(genders))\n",
    "    per_by_age = clean_age_percents(parse_row_2(ages))\n",
    "\n",
    "    def get_rate_2(sex, age):\n",
    "        if sex == 0:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1]\n",
    "                    else:\n",
    "                        return row[1]\n",
    "            except:\n",
    "                return np.nan\n",
    "        else:\n",
    "            try:\n",
    "                age = int(age)\n",
    "                for i, row in enumerate(per_by_age):\n",
    "                    if i < len(per_by_age) - 1:\n",
    "                        if age <= row[0]:\n",
    "                            return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "                    else:\n",
    "                        return row[1] * per_by_gender['man'] / per_by_gender['woman']\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "    # Register the UDF\n",
    "    get_rate_2_udf = F.udf(lambda sex, age: get_rate_2(sex, age) / 100, DoubleType())\n",
    "\n",
    "    data = data.withColumn('smoke_2', when(col('smoke_2').isNull(), get_rate_2_udf(col('sex'), col('age'))).otherwise(col('smoke_2')))\n",
    "\n",
    "    return data \n",
    "\n",
    "def impute_smoke(data: DataFrame) -> DataFrame:\n",
    "    data = data.withColumn('smoke_1', F.col('smoke'))\n",
    "    data = data.withColumn('smoke_2', F.col('smoke'))\n",
    "\n",
    "    data = smoke_1(data)\n",
    "    data = smoke_2(data)\n",
    "\n",
    "    data = data.drop('smoke')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d54632-f481-4f72-bc1d-c9a66a1fb582",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce311d12-501d-46f3-8fbd-0ddcb4315d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CompositeEvaluator\n",
    "class CompositeEvaluator(Evaluator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.auc_evaluator = BinaryClassificationEvaluator(labelCol=\"target\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "        self.accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        self.precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "        self.recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "        self.f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "        self.weights = {\n",
    "            \"AUC\": 0.4,\n",
    "            \"accuracy\": 0.2,\n",
    "            \"precision\": 0.1,\n",
    "            \"recall\": 0.1,\n",
    "            \"f1\": 0.2\n",
    "        }\n",
    "\n",
    "    def isLargerBetter(self):\n",
    "        return True\n",
    "\n",
    "    def _evaluate(self, dataset):\n",
    "        auc = self.auc_evaluator.evaluate(dataset)\n",
    "        accuracy = self.accuracy_evaluator.evaluate(dataset)\n",
    "        precision = self.precision_evaluator.evaluate(dataset)\n",
    "        recall = self.recall_evaluator.evaluate(dataset)\n",
    "        f1 = self.f1_evaluator.evaluate(dataset)\n",
    "\n",
    "        composite_score = (self.weights[\"AUC\"] * auc +\n",
    "                           self.weights[\"accuracy\"] * accuracy +\n",
    "                           self.weights[\"precision\"] * precision +\n",
    "                           self.weights[\"recall\"] * recall +\n",
    "                           self.weights[\"f1\"] * f1)\n",
    "\n",
    "        return composite_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83af3760-edd2-4965-b655-34539851c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data: DataFrame):\n",
    "\n",
    "    # clean\n",
    "    data = retain_cols(data)\n",
    "    data = replace_out_of_range(data)\n",
    "\n",
    "    # drop null targets\n",
    "    data = data.dropna(subset=[\"target\"])\n",
    "\n",
    "    # make age an int\n",
    "    data = data.withColumn(\"age\", data[\"age\"].cast(IntegerType()))\n",
    "\n",
    "    numeric_features = [f.name for f in data.schema.fields if isinstance(f.dataType, (DoubleType, FloatType, IntegerType, LongType))]\n",
    "    numeric_features.remove(\"target\")\n",
    "\n",
    "    # numeric columns\n",
    "    imputed_columns = [f\"Imputed{v}\" for v in numeric_features]\n",
    "    imputer_numeric = Imputer(inputCols=numeric_features, outputCols=imputed_columns, strategy = \"mean\")\n",
    "\n",
    "\n",
    "    data.show()\n",
    "    \n",
    "    # Assemble feature columns into a single feature vector\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=imputed_columns, \n",
    "        outputCol=\"features\"\n",
    "        )\n",
    "\n",
    "    # Define binary classification models\n",
    "    classifiers = {\n",
    "        \"RandomForest\": RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\"),\n",
    "        \"LogisticRegression\": LogisticRegression(labelCol=\"target\", featuresCol=\"features\"),\n",
    "        \"GBTClassifier\": GBTClassifier(labelCol=\"target\", featuresCol=\"features\"),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\")\n",
    "\n",
    "    }\n",
    "\n",
    "    # Define parameter grids for each classifier\n",
    "    param_grids = {\n",
    "        \"RandomForest\": ParamGridBuilder() \\\n",
    "            .addGrid(classifiers[\"RandomForest\"].maxDepth, [4, 6, 8]) \\\n",
    "            .addGrid(classifiers[\"RandomForest\"].numTrees, [50, 100]) \\\n",
    "            .build(),\n",
    "        \"LogisticRegression\": ParamGridBuilder() \\\n",
    "            .addGrid(classifiers[\"LogisticRegression\"].regParam, [0.01, 0.1]) \\\n",
    "            .build(),\n",
    "        \"GBTClassifier\": ParamGridBuilder() \\\n",
    "            .addGrid(classifiers[\"GBTClassifier\"].maxDepth, [4, 6, 8]) \\\n",
    "            .addGrid(classifiers[\"GBTClassifier\"].maxIter, [20, 50]) \\\n",
    "            .build(),\n",
    "        \"DecisionTree\": ParamGridBuilder() \\\n",
    "            .addGrid(classifiers[\"DecisionTree\"].maxDepth, [4, 6, 8]) \\\n",
    "            .addGrid(classifiers[\"DecisionTree\"].minInstancesPerNode, [1, 2, 4]) \\\n",
    "            .build()\n",
    "    }\n",
    "    \n",
    "    # Set up the composite evaluator\n",
    "    composite_evaluator = CompositeEvaluator()\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = data.randomSplit([TRAIN_TEST_SPLIT, 1-TRAIN_TEST_SPLIT], seed=SPLIT_SEED)\n",
    "\n",
    "    # Cache the training data to improve performance\n",
    "    train_data.cache()\n",
    "\n",
    "    best_model = None\n",
    "    best_model_name = \"\"\n",
    "    best_composite_score = float('-inf')\n",
    "    \n",
    "    # Iterate through each classifier\n",
    "    for model_name, classifier in classifiers.items():\n",
    "        # Create the pipeline\n",
    "        pipeline = Pipeline(stages=[imputer_numeric, assembler, classifier])  \n",
    "\n",
    "        # Set up the cross-validator\n",
    "        crossval = CrossValidator(\n",
    "            estimator=pipeline,\n",
    "            estimatorParamMaps=param_grids[model_name],\n",
    "            evaluator=composite_evaluator,\n",
    "            numFolds=NUMBER_OF_FOLDS,\n",
    "            seed=SPLIT_SEED)\n",
    "\n",
    "        # Train the cross-validated pipeline model\n",
    "        cvModel = crossval.fit(train_data)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        predictions = cvModel.transform(test_data)\n",
    "\n",
    "        # Evaluate the model using the composite score\n",
    "        composite_score = composite_evaluator.evaluate(predictions)\n",
    "        print(f\"{model_name} Composite Score: {composite_score:.4f}\")\n",
    "\n",
    "        # Update the best model if current model is better\n",
    "        if composite_score > best_composite_score:\n",
    "            best_composite_score = composite_score\n",
    "            best_model = cvModel.bestModel.stages[-1]\n",
    "            best_model_name = model_name\n",
    "            best_metrics = {\n",
    "                \"composite_score\": composite_score,\n",
    "                \"AUC\": composite_evaluator.auc_evaluator.evaluate(predictions),\n",
    "                \"accuracy\": composite_evaluator.accuracy_evaluator.evaluate(predictions),\n",
    "                \"precision\": composite_evaluator.precision_evaluator.evaluate(predictions),\n",
    "                \"recall\": composite_evaluator.recall_evaluator.evaluate(predictions),\n",
    "                \"f1\": composite_evaluator.f1_evaluator.evaluate(predictions)\n",
    "            }\n",
    "            \n",
    "    # Print the best model information\n",
    "    print(f\"Best Model: {best_model_name}\")\n",
    "    print(f\"Best Model Composite Score: {best_composite_score:.4f}\")\n",
    "    print(f\"Best Model Metrics - AUC: {best_metrics['AUC']:.4f}, Accuracy: {best_metrics['accuracy']:.4f}, Precision: {best_metrics['precision']:.4f}, Recall: {best_metrics['recall']:.4f}, F1-Score: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "\n",
    "    # Retrieve and print the best model parameters\n",
    "    if best_model_name == \"RandomForest\":\n",
    "        selected_max_depth = best_model.getOrDefault(best_model.getParam(\"maxDepth\"))\n",
    "        selected_num_trees = best_model.getOrDefault(best_model.getParam(\"numTrees\"))\n",
    "        print(f\"Selected Maximum Tree Depth: {selected_max_depth}\")\n",
    "        print(f\"Selected Number of Trees: {selected_num_trees}\")\n",
    "    elif best_model_name == \"LogisticRegression\":\n",
    "        selected_reg_param = best_model.getOrDefault(best_model.getParam(\"regParam\"))\n",
    "        print(f\"Selected Regularization Parameter: {selected_reg_param}\")\n",
    "    elif best_model_name == \"GBTClassifier\":\n",
    "        selected_max_depth = best_model.getOrDefault(best_model.getParam(\"maxDepth\"))\n",
    "        selected_max_iter = best_model.getOrDefault(best_model.getParam(\"maxIter\"))\n",
    "        print(f\"Selected Maximum Tree Depth: {selected_max_depth}\")\n",
    "        print(f\"Selected Maximum Iterations: {selected_max_iter}\")\n",
    "    elif best_model_name == \"DecisionTree\":\n",
    "        selected_max_depth = best_model.getOrDefault(best_model.getParam(\"maxDepth\"))\n",
    "        selected_min_instances_per_node = best_model.getOrDefault(best_model.getParam(\"minInstancesPerNode\"))\n",
    "        print(f\"Selected Maximum Tree Depth: {selected_max_depth}\")\n",
    "        print(f\"Selected Minimum Instances Per Node: {selected_min_instances_per_node}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd295f28-eb11-445f-90ee-081db6e2941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_spark_configurations():\n",
    "    conf = SparkConf()\n",
    "    conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"50MB\")\n",
    "    conf.set(\"spark.driver.memory\", \"8g\")\n",
    "    conf.set(\"spark.executor.memory\", \"8g\")\n",
    "    conf.set(\"spark.executor.cores\", \"4\")\n",
    "    conf.set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    return conf\n",
    "\n",
    "def main():\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Predict Heart Disease\") \\\n",
    "        .config(conf=set_spark_configurations()) \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"512m\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "    data = read_data(spark)\n",
    "    \n",
    "    pipeline(data)\n",
    "\n",
    "\n",
    "\n",
    "    spark.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95c1a82-6bdf-4871-9706-5c464430701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/27 17:36:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+--------+---+--------+-----+---+----+----+---+--------+-------+-------+-----+-------+-----+------+\n",
      "|age|sex|painloc|painexer| cp|trestbps|smoke|fbs|prop|nitr|pro|diuretic|thaldur|thalach|exang|oldpeak|slope|target|\n",
      "+---+---+-------+--------+---+--------+-----+---+----+----+---+--------+-------+-------+-----+-------+-----+------+\n",
      "| 63|  1|   null|    null|  1|     145| null|  1|   0|   0|  0|       0|   10.5|    150|    0|    2.3|    3|     0|\n",
      "| 67|  1|   null|    null|  4|     160| null|  0|   1|   0|  0|       0|    9.5|    108|    1|    1.5|    2|     1|\n",
      "| 67|  1|   null|    null|  4|     120| null|  0|   1|   0|  0|       0|    8.5|    129|    1|    2.6|    2|     1|\n",
      "| 37|  1|   null|    null|  3|     130| null|  0|   1|   0|  0|       0|   13.0|    187|    0|    3.5|    3|     0|\n",
      "| 41|  0|   null|    null|  2|     130| null|  0|   0|   0|  0|       0|    7.0|    172|    0|    1.4|    1|     0|\n",
      "| 56|  1|   null|    null|  2|     120| null|  0|   0|   0|  0|       0|   11.3|    178|    0|    0.8|    1|     0|\n",
      "| 62|  0|   null|    null|  4|     140| null|  0|   0|   0|  0|       0|    6.0|    160|    0|    3.6|    3|     1|\n",
      "| 57|  0|   null|    null|  4|     120| null|  0|   0|   0|  0|       0|    9.0|    163|    1|    0.6|    1|     0|\n",
      "| 63|  1|   null|    null|  4|     130| null|  0|   1|   1|  0|       0|    8.0|    147|    0|    1.4|    2|     1|\n",
      "| 53|  1|   null|    null|  4|     140| null|  1|   1|   0|  0|       1|    5.5|    155|    1|    3.1|    3|     1|\n",
      "| 57|  1|   null|    null|  4|     140| null|  0|   0|   0|  0|       0|    8.2|    148|    0|    0.4|    2|     0|\n",
      "| 56|  0|   null|    null|  2|     140| null|  0|   1|   1|  0|       0|    4.5|    153|    0|    1.3|    2|     0|\n",
      "| 56|  1|   null|    null|  3|     130| null|  1|   0|   0|  0|       0|   13.0|    142|    1|    0.6|    2|     1|\n",
      "| 44|  1|   null|    null|  2|     120| null|  0|   1|   0|  0|       0|    9.3|    173|    0|    0.0|    1|     0|\n",
      "| 52|  1|   null|    null|  3|     172| null|  1|   0|   0|  0|       0|   12.5|    162|    0|    0.5|    1|     0|\n",
      "| 57|  1|   null|    null|  3|     150| null|  0|   0|   1|  0|       0|   11.0|    174|    0|    1.6|    1|     0|\n",
      "| 48|  1|   null|    null|  2|     110| null|  0|   1|   0|  0|       0|    9.8|    168|    0|    1.0|    3|     1|\n",
      "| 54|  1|   null|    null|  4|     140| null|  0|   0|   0|  0|       1|    7.8|    160|    0|    1.2|    1|     0|\n",
      "| 48|  0|   null|    null|  3|     130| null|  0|   0|   0|  0|       0|   10.0|    139|    0|    0.2|    1|     0|\n",
      "| 49|  1|   null|    null|  2|     130| null|  0|   0|   0|  0|       0|   12.0|    171|    0|    0.6|    1|     0|\n",
      "+---+---+-------+--------+---+--------+-----+---+----+----+---+--------+-------+-------+-----+-------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 17:36:42 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/05/27 17:37:30 WARN DAGScheduler: Broadcasting large task binary with size 1138.6 KiB\n",
      "24/05/27 17:37:31 WARN DAGScheduler: Broadcasting large task binary with size 1482.2 KiB\n",
      "24/05/27 17:37:32 WARN DAGScheduler: Broadcasting large task binary with size 1184.3 KiB\n",
      "24/05/27 17:37:33 WARN DAGScheduler: Broadcasting large task binary with size 1196.9 KiB\n",
      "24/05/27 17:37:33 WARN DAGScheduler: Broadcasting large task binary with size 1196.9 KiB\n",
      "24/05/27 17:37:33 WARN DAGScheduler: Broadcasting large task binary with size 1196.9 KiB\n",
      "24/05/27 17:37:34 WARN DAGScheduler: Broadcasting large task binary with size 1196.9 KiB\n",
      "24/05/27 17:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1142.0 KiB\n",
      "24/05/27 17:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1460.4 KiB\n",
      "24/05/27 17:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1159.6 KiB\n",
      "24/05/27 17:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1172.2 KiB\n",
      "24/05/27 17:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1172.2 KiB\n",
      "24/05/27 17:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1172.2 KiB\n",
      "24/05/27 17:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1172.2 KiB\n",
      "24/05/27 17:40:07 WARN DAGScheduler: Broadcasting large task binary with size 1149.9 KiB\n",
      "24/05/27 17:40:08 WARN DAGScheduler: Broadcasting large task binary with size 1480.6 KiB\n",
      "24/05/27 17:40:09 WARN DAGScheduler: Broadcasting large task binary with size 1176.0 KiB\n",
      "24/05/27 17:40:09 WARN DAGScheduler: Broadcasting large task binary with size 1188.6 KiB\n",
      "24/05/27 17:40:09 WARN DAGScheduler: Broadcasting large task binary with size 1188.6 KiB\n",
      "24/05/27 17:40:10 WARN DAGScheduler: Broadcasting large task binary with size 1188.6 KiB\n",
      "24/05/27 17:40:10 WARN DAGScheduler: Broadcasting large task binary with size 1188.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Composite Score: 0.8103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 17:40:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/27 17:40:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Composite Score: 0.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 18:05:10 WARN DAGScheduler: Broadcasting large task binary with size 1000.7 KiB\n",
      "24/05/27 18:05:11 WARN DAGScheduler: Broadcasting large task binary with size 1007.3 KiB\n",
      "24/05/27 18:05:12 WARN DAGScheduler: Broadcasting large task binary with size 1017.2 KiB\n",
      "24/05/27 18:05:14 WARN DAGScheduler: Broadcasting large task binary with size 1015.9 KiB\n",
      "24/05/27 18:05:15 WARN DAGScheduler: Broadcasting large task binary with size 1016.4 KiB\n",
      "24/05/27 18:05:16 WARN DAGScheduler: Broadcasting large task binary with size 1016.9 KiB\n",
      "24/05/27 18:05:17 WARN DAGScheduler: Broadcasting large task binary with size 1018.0 KiB\n",
      "24/05/27 18:05:18 WARN DAGScheduler: Broadcasting large task binary with size 1020.0 KiB\n",
      "24/05/27 18:05:19 WARN DAGScheduler: Broadcasting large task binary with size 1023.8 KiB\n",
      "24/05/27 18:05:20 WARN DAGScheduler: Broadcasting large task binary with size 1029.9 KiB\n",
      "24/05/27 18:05:21 WARN DAGScheduler: Broadcasting large task binary with size 1038.8 KiB\n",
      "24/05/27 18:05:22 WARN DAGScheduler: Broadcasting large task binary with size 1037.5 KiB\n",
      "24/05/27 18:05:24 WARN DAGScheduler: Broadcasting large task binary with size 1038.0 KiB\n",
      "24/05/27 18:05:24 WARN DAGScheduler: Broadcasting large task binary with size 1038.6 KiB\n",
      "24/05/27 18:05:26 WARN DAGScheduler: Broadcasting large task binary with size 1039.7 KiB\n",
      "24/05/27 18:05:27 WARN DAGScheduler: Broadcasting large task binary with size 1042.0 KiB\n",
      "24/05/27 18:05:28 WARN DAGScheduler: Broadcasting large task binary with size 1046.3 KiB\n",
      "24/05/27 18:05:29 WARN DAGScheduler: Broadcasting large task binary with size 1052.8 KiB\n",
      "24/05/27 18:05:30 WARN DAGScheduler: Broadcasting large task binary with size 1061.8 KiB\n",
      "24/05/27 18:05:31 WARN DAGScheduler: Broadcasting large task binary with size 1060.6 KiB\n",
      "24/05/27 18:05:32 WARN DAGScheduler: Broadcasting large task binary with size 1061.1 KiB\n",
      "24/05/27 18:05:33 WARN DAGScheduler: Broadcasting large task binary with size 1061.7 KiB\n",
      "24/05/27 18:05:34 WARN DAGScheduler: Broadcasting large task binary with size 1062.8 KiB\n",
      "24/05/27 18:05:35 WARN DAGScheduler: Broadcasting large task binary with size 1064.8 KiB\n",
      "24/05/27 18:05:36 WARN DAGScheduler: Broadcasting large task binary with size 1068.6 KiB\n",
      "24/05/27 18:05:37 WARN DAGScheduler: Broadcasting large task binary with size 1074.4 KiB\n",
      "24/05/27 18:05:38 WARN DAGScheduler: Broadcasting large task binary with size 1083.6 KiB\n",
      "24/05/27 18:05:40 WARN DAGScheduler: Broadcasting large task binary with size 1082.8 KiB\n",
      "24/05/27 18:05:41 WARN DAGScheduler: Broadcasting large task binary with size 1083.3 KiB\n",
      "24/05/27 18:05:42 WARN DAGScheduler: Broadcasting large task binary with size 1083.9 KiB\n",
      "24/05/27 18:05:43 WARN DAGScheduler: Broadcasting large task binary with size 1085.0 KiB\n",
      "24/05/27 18:05:44 WARN DAGScheduler: Broadcasting large task binary with size 1087.0 KiB\n",
      "24/05/27 18:05:45 WARN DAGScheduler: Broadcasting large task binary with size 1090.8 KiB\n",
      "24/05/27 18:05:47 WARN DAGScheduler: Broadcasting large task binary with size 1096.9 KiB\n",
      "24/05/27 18:05:48 WARN DAGScheduler: Broadcasting large task binary with size 1106.6 KiB\n",
      "24/05/27 18:05:50 WARN DAGScheduler: Broadcasting large task binary with size 1105.4 KiB\n",
      "24/05/27 18:05:51 WARN DAGScheduler: Broadcasting large task binary with size 1105.9 KiB\n",
      "24/05/27 18:05:52 WARN DAGScheduler: Broadcasting large task binary with size 1106.4 KiB\n",
      "24/05/27 18:05:53 WARN DAGScheduler: Broadcasting large task binary with size 1107.5 KiB\n",
      "24/05/27 18:05:54 WARN DAGScheduler: Broadcasting large task binary with size 1109.8 KiB\n",
      "24/05/27 18:05:55 WARN DAGScheduler: Broadcasting large task binary with size 1114.2 KiB\n",
      "24/05/27 18:05:56 WARN DAGScheduler: Broadcasting large task binary with size 1121.3 KiB\n",
      "24/05/27 18:05:57 WARN DAGScheduler: Broadcasting large task binary with size 1130.9 KiB\n",
      "24/05/27 18:05:59 WARN DAGScheduler: Broadcasting large task binary with size 1128.8 KiB\n",
      "24/05/27 18:06:00 WARN DAGScheduler: Broadcasting large task binary with size 1129.3 KiB\n",
      "24/05/27 18:06:01 WARN DAGScheduler: Broadcasting large task binary with size 1129.8 KiB\n",
      "24/05/27 18:06:02 WARN DAGScheduler: Broadcasting large task binary with size 1131.0 KiB\n",
      "24/05/27 18:06:03 WARN DAGScheduler: Broadcasting large task binary with size 1133.2 KiB\n",
      "24/05/27 18:06:04 WARN DAGScheduler: Broadcasting large task binary with size 1137.6 KiB\n",
      "24/05/27 18:06:06 WARN DAGScheduler: Broadcasting large task binary with size 1144.7 KiB\n",
      "24/05/27 18:06:07 WARN DAGScheduler: Broadcasting large task binary with size 1154.4 KiB\n",
      "24/05/27 18:06:08 WARN DAGScheduler: Broadcasting large task binary with size 1152.2 KiB\n",
      "24/05/27 18:06:09 WARN DAGScheduler: Broadcasting large task binary with size 1152.7 KiB\n",
      "24/05/27 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1153.3 KiB\n",
      "24/05/27 18:06:11 WARN DAGScheduler: Broadcasting large task binary with size 1154.4 KiB\n",
      "24/05/27 18:06:12 WARN DAGScheduler: Broadcasting large task binary with size 1156.7 KiB\n",
      "24/05/27 18:06:14 WARN DAGScheduler: Broadcasting large task binary with size 1161.1 KiB\n",
      "24/05/27 18:06:15 WARN DAGScheduler: Broadcasting large task binary with size 1168.4 KiB\n",
      "24/05/27 18:06:16 WARN DAGScheduler: Broadcasting large task binary with size 1178.9 KiB\n",
      "24/05/27 18:06:18 WARN DAGScheduler: Broadcasting large task binary with size 1177.0 KiB\n",
      "24/05/27 18:06:19 WARN DAGScheduler: Broadcasting large task binary with size 1177.5 KiB\n",
      "24/05/27 18:06:20 WARN DAGScheduler: Broadcasting large task binary with size 1178.1 KiB\n",
      "24/05/27 18:06:21 WARN DAGScheduler: Broadcasting large task binary with size 1179.2 KiB\n",
      "24/05/27 18:06:22 WARN DAGScheduler: Broadcasting large task binary with size 1181.5 KiB\n",
      "24/05/27 18:06:23 WARN DAGScheduler: Broadcasting large task binary with size 1185.9 KiB\n",
      "24/05/27 18:06:25 WARN DAGScheduler: Broadcasting large task binary with size 1193.4 KiB\n",
      "24/05/27 18:06:26 WARN DAGScheduler: Broadcasting large task binary with size 1203.2 KiB\n",
      "24/05/27 18:06:27 WARN DAGScheduler: Broadcasting large task binary with size 1201.4 KiB\n",
      "24/05/27 18:06:34 WARN DAGScheduler: Broadcasting large task binary with size 1201.9 KiB\n",
      "24/05/27 18:06:36 WARN DAGScheduler: Broadcasting large task binary with size 1202.4 KiB\n",
      "24/05/27 18:06:37 WARN DAGScheduler: Broadcasting large task binary with size 1203.6 KiB\n",
      "24/05/27 18:06:38 WARN DAGScheduler: Broadcasting large task binary with size 1205.8 KiB\n",
      "24/05/27 18:06:39 WARN DAGScheduler: Broadcasting large task binary with size 1210.3 KiB\n",
      "24/05/27 18:06:40 WARN DAGScheduler: Broadcasting large task binary with size 1217.9 KiB\n",
      "24/05/27 18:06:41 WARN DAGScheduler: Broadcasting large task binary with size 1228.1 KiB\n",
      "24/05/27 18:06:44 WARN DAGScheduler: Broadcasting large task binary with size 1225.9 KiB\n",
      "24/05/27 18:06:45 WARN DAGScheduler: Broadcasting large task binary with size 1226.4 KiB\n",
      "24/05/27 18:06:46 WARN DAGScheduler: Broadcasting large task binary with size 1227.0 KiB\n",
      "24/05/27 18:06:47 WARN DAGScheduler: Broadcasting large task binary with size 1228.1 KiB\n",
      "24/05/27 18:06:48 WARN DAGScheduler: Broadcasting large task binary with size 1230.4 KiB\n",
      "24/05/27 18:06:49 WARN DAGScheduler: Broadcasting large task binary with size 1234.8 KiB\n",
      "24/05/27 18:06:51 WARN DAGScheduler: Broadcasting large task binary with size 1242.1 KiB\n",
      "24/05/27 18:06:52 WARN DAGScheduler: Broadcasting large task binary with size 1252.3 KiB\n",
      "24/05/27 18:06:53 WARN DAGScheduler: Broadcasting large task binary with size 1250.0 KiB\n",
      "24/05/27 18:06:55 WARN DAGScheduler: Broadcasting large task binary with size 1250.5 KiB\n",
      "24/05/27 18:06:56 WARN DAGScheduler: Broadcasting large task binary with size 1251.0 KiB\n",
      "24/05/27 18:06:57 WARN DAGScheduler: Broadcasting large task binary with size 1252.1 KiB\n",
      "24/05/27 18:06:58 WARN DAGScheduler: Broadcasting large task binary with size 1254.4 KiB\n",
      "24/05/27 18:06:59 WARN DAGScheduler: Broadcasting large task binary with size 1258.8 KiB\n",
      "24/05/27 18:07:00 WARN DAGScheduler: Broadcasting large task binary with size 1266.1 KiB\n",
      "24/05/27 18:07:02 WARN DAGScheduler: Broadcasting large task binary with size 1275.8 KiB\n",
      "24/05/27 18:07:03 WARN DAGScheduler: Broadcasting large task binary with size 1273.8 KiB\n",
      "24/05/27 18:07:05 WARN DAGScheduler: Broadcasting large task binary with size 1274.3 KiB\n",
      "24/05/27 18:07:06 WARN DAGScheduler: Broadcasting large task binary with size 1274.9 KiB\n",
      "24/05/27 18:07:07 WARN DAGScheduler: Broadcasting large task binary with size 1276.0 KiB\n",
      "24/05/27 18:07:08 WARN DAGScheduler: Broadcasting large task binary with size 1278.3 KiB\n",
      "24/05/27 18:07:09 WARN DAGScheduler: Broadcasting large task binary with size 1282.6 KiB\n",
      "24/05/27 18:07:10 WARN DAGScheduler: Broadcasting large task binary with size 1289.6 KiB\n",
      "24/05/27 18:07:12 WARN DAGScheduler: Broadcasting large task binary with size 1298.1 KiB\n",
      "24/05/27 18:07:16 WARN DAGScheduler: Broadcasting large task binary with size 1269.4 KiB\n",
      "24/05/27 18:07:19 WARN DAGScheduler: Broadcasting large task binary with size 1281.9 KiB\n",
      "24/05/27 18:07:21 WARN DAGScheduler: Broadcasting large task binary with size 1281.9 KiB\n",
      "24/05/27 18:07:24 WARN DAGScheduler: Broadcasting large task binary with size 1281.9 KiB\n",
      "24/05/27 18:07:27 WARN DAGScheduler: Broadcasting large task binary with size 1281.9 KiB\n",
      "24/05/27 18:23:03 WARN DAGScheduler: Broadcasting large task binary with size 1001.6 KiB\n",
      "24/05/27 18:23:04 WARN DAGScheduler: Broadcasting large task binary with size 1008.7 KiB\n",
      "24/05/27 18:23:05 WARN DAGScheduler: Broadcasting large task binary with size 1019.6 KiB\n",
      "24/05/27 18:23:06 WARN DAGScheduler: Broadcasting large task binary with size 1019.0 KiB\n",
      "24/05/27 18:23:07 WARN DAGScheduler: Broadcasting large task binary with size 1019.4 KiB\n",
      "24/05/27 18:23:08 WARN DAGScheduler: Broadcasting large task binary with size 1020.0 KiB\n",
      "24/05/27 18:23:09 WARN DAGScheduler: Broadcasting large task binary with size 1021.1 KiB\n",
      "24/05/27 18:23:10 WARN DAGScheduler: Broadcasting large task binary with size 1023.4 KiB\n",
      "24/05/27 18:23:11 WARN DAGScheduler: Broadcasting large task binary with size 1027.5 KiB\n",
      "24/05/27 18:23:12 WARN DAGScheduler: Broadcasting large task binary with size 1034.7 KiB\n",
      "24/05/27 18:23:13 WARN DAGScheduler: Broadcasting large task binary with size 1045.3 KiB\n",
      "24/05/27 18:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1044.6 KiB\n",
      "24/05/27 18:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1045.1 KiB\n",
      "24/05/27 18:23:16 WARN DAGScheduler: Broadcasting large task binary with size 1045.7 KiB\n",
      "24/05/27 18:23:17 WARN DAGScheduler: Broadcasting large task binary with size 1046.8 KiB\n",
      "24/05/27 18:23:18 WARN DAGScheduler: Broadcasting large task binary with size 1049.0 KiB\n",
      "24/05/27 18:23:19 WARN DAGScheduler: Broadcasting large task binary with size 1053.2 KiB\n",
      "24/05/27 18:23:20 WARN DAGScheduler: Broadcasting large task binary with size 1060.3 KiB\n",
      "24/05/27 18:23:21 WARN DAGScheduler: Broadcasting large task binary with size 1071.3 KiB\n",
      "24/05/27 18:23:23 WARN DAGScheduler: Broadcasting large task binary with size 1070.8 KiB\n",
      "24/05/27 18:23:24 WARN DAGScheduler: Broadcasting large task binary with size 1071.2 KiB\n",
      "24/05/27 18:23:25 WARN DAGScheduler: Broadcasting large task binary with size 1071.8 KiB\n",
      "24/05/27 18:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1072.9 KiB\n",
      "24/05/27 18:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1075.2 KiB\n",
      "24/05/27 18:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1079.1 KiB\n",
      "24/05/27 18:23:29 WARN DAGScheduler: Broadcasting large task binary with size 1086.5 KiB\n",
      "24/05/27 18:23:30 WARN DAGScheduler: Broadcasting large task binary with size 1097.5 KiB\n",
      "24/05/27 18:23:31 WARN DAGScheduler: Broadcasting large task binary with size 1096.9 KiB\n",
      "24/05/27 18:23:33 WARN DAGScheduler: Broadcasting large task binary with size 1097.4 KiB\n",
      "24/05/27 18:23:33 WARN DAGScheduler: Broadcasting large task binary with size 1098.0 KiB\n",
      "24/05/27 18:23:34 WARN DAGScheduler: Broadcasting large task binary with size 1099.1 KiB\n",
      "24/05/27 18:23:35 WARN DAGScheduler: Broadcasting large task binary with size 1101.3 KiB\n",
      "24/05/27 18:23:36 WARN DAGScheduler: Broadcasting large task binary with size 1105.3 KiB\n",
      "24/05/27 18:23:37 WARN DAGScheduler: Broadcasting large task binary with size 1112.6 KiB\n",
      "24/05/27 18:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1123.6 KiB\n",
      "24/05/27 18:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1123.0 KiB\n",
      "24/05/27 18:23:41 WARN DAGScheduler: Broadcasting large task binary with size 1123.4 KiB\n",
      "24/05/27 18:23:42 WARN DAGScheduler: Broadcasting large task binary with size 1124.0 KiB\n",
      "24/05/27 18:23:43 WARN DAGScheduler: Broadcasting large task binary with size 1125.2 KiB\n",
      "24/05/27 18:23:44 WARN DAGScheduler: Broadcasting large task binary with size 1127.4 KiB\n",
      "24/05/27 18:23:45 WARN DAGScheduler: Broadcasting large task binary with size 1131.2 KiB\n",
      "24/05/27 18:23:47 WARN DAGScheduler: Broadcasting large task binary with size 1137.9 KiB\n",
      "24/05/27 18:23:49 WARN DAGScheduler: Broadcasting large task binary with size 1148.5 KiB\n",
      "24/05/27 18:23:51 WARN DAGScheduler: Broadcasting large task binary with size 1147.8 KiB\n",
      "24/05/27 18:23:53 WARN DAGScheduler: Broadcasting large task binary with size 1148.3 KiB\n",
      "24/05/27 18:23:54 WARN DAGScheduler: Broadcasting large task binary with size 1148.8 KiB\n",
      "24/05/27 18:23:55 WARN DAGScheduler: Broadcasting large task binary with size 1150.0 KiB\n",
      "24/05/27 18:23:56 WARN DAGScheduler: Broadcasting large task binary with size 1152.2 KiB\n",
      "24/05/27 18:23:57 WARN DAGScheduler: Broadcasting large task binary with size 1156.3 KiB\n",
      "24/05/27 18:23:58 WARN DAGScheduler: Broadcasting large task binary with size 1163.5 KiB\n",
      "24/05/27 18:24:00 WARN DAGScheduler: Broadcasting large task binary with size 1174.5 KiB\n",
      "24/05/27 18:24:01 WARN DAGScheduler: Broadcasting large task binary with size 1174.0 KiB\n",
      "24/05/27 18:24:02 WARN DAGScheduler: Broadcasting large task binary with size 1174.4 KiB\n",
      "24/05/27 18:24:03 WARN DAGScheduler: Broadcasting large task binary with size 1175.0 KiB\n",
      "24/05/27 18:24:05 WARN DAGScheduler: Broadcasting large task binary with size 1176.1 KiB\n",
      "24/05/27 18:24:06 WARN DAGScheduler: Broadcasting large task binary with size 1178.4 KiB\n",
      "24/05/27 18:24:07 WARN DAGScheduler: Broadcasting large task binary with size 1182.2 KiB\n",
      "24/05/27 18:24:08 WARN DAGScheduler: Broadcasting large task binary with size 1188.9 KiB\n",
      "24/05/27 18:24:09 WARN DAGScheduler: Broadcasting large task binary with size 1199.5 KiB\n",
      "24/05/27 18:24:11 WARN DAGScheduler: Broadcasting large task binary with size 1198.8 KiB\n",
      "24/05/27 18:24:12 WARN DAGScheduler: Broadcasting large task binary with size 1199.3 KiB\n",
      "24/05/27 18:24:13 WARN DAGScheduler: Broadcasting large task binary with size 1199.9 KiB\n",
      "24/05/27 18:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "24/05/27 18:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1203.3 KiB\n",
      "24/05/27 18:24:16 WARN DAGScheduler: Broadcasting large task binary with size 1207.4 KiB\n",
      "24/05/27 18:24:17 WARN DAGScheduler: Broadcasting large task binary with size 1214.5 KiB\n",
      "24/05/27 18:24:18 WARN DAGScheduler: Broadcasting large task binary with size 1225.6 KiB\n",
      "24/05/27 18:24:20 WARN DAGScheduler: Broadcasting large task binary with size 1225.2 KiB\n",
      "24/05/27 18:24:21 WARN DAGScheduler: Broadcasting large task binary with size 1225.7 KiB\n",
      "24/05/27 18:24:22 WARN DAGScheduler: Broadcasting large task binary with size 1226.3 KiB\n",
      "24/05/27 18:24:23 WARN DAGScheduler: Broadcasting large task binary with size 1227.4 KiB\n",
      "24/05/27 18:24:25 WARN DAGScheduler: Broadcasting large task binary with size 1229.7 KiB\n",
      "24/05/27 18:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1233.8 KiB\n",
      "24/05/27 18:24:27 WARN DAGScheduler: Broadcasting large task binary with size 1240.4 KiB\n",
      "24/05/27 18:24:28 WARN DAGScheduler: Broadcasting large task binary with size 1250.7 KiB\n",
      "24/05/27 18:24:29 WARN DAGScheduler: Broadcasting large task binary with size 1249.8 KiB\n",
      "24/05/27 18:24:31 WARN DAGScheduler: Broadcasting large task binary with size 1250.2 KiB\n",
      "24/05/27 18:24:32 WARN DAGScheduler: Broadcasting large task binary with size 1250.8 KiB\n",
      "24/05/27 18:24:33 WARN DAGScheduler: Broadcasting large task binary with size 1251.9 KiB\n",
      "24/05/27 18:24:34 WARN DAGScheduler: Broadcasting large task binary with size 1254.2 KiB\n",
      "24/05/27 18:24:35 WARN DAGScheduler: Broadcasting large task binary with size 1258.3 KiB\n",
      "24/05/27 18:24:36 WARN DAGScheduler: Broadcasting large task binary with size 1264.9 KiB\n",
      "24/05/27 18:24:37 WARN DAGScheduler: Broadcasting large task binary with size 1275.2 KiB\n",
      "24/05/27 18:24:39 WARN DAGScheduler: Broadcasting large task binary with size 1274.3 KiB\n",
      "24/05/27 18:24:40 WARN DAGScheduler: Broadcasting large task binary with size 1274.7 KiB\n",
      "24/05/27 18:24:41 WARN DAGScheduler: Broadcasting large task binary with size 1275.3 KiB\n",
      "24/05/27 18:24:43 WARN DAGScheduler: Broadcasting large task binary with size 1276.4 KiB\n",
      "24/05/27 18:24:44 WARN DAGScheduler: Broadcasting large task binary with size 1278.7 KiB\n",
      "24/05/27 18:24:45 WARN DAGScheduler: Broadcasting large task binary with size 1282.8 KiB\n",
      "24/05/27 18:24:46 WARN DAGScheduler: Broadcasting large task binary with size 1289.7 KiB\n",
      "24/05/27 18:24:47 WARN DAGScheduler: Broadcasting large task binary with size 1300.9 KiB\n",
      "24/05/27 18:24:48 WARN DAGScheduler: Broadcasting large task binary with size 1300.3 KiB\n",
      "24/05/27 18:24:50 WARN DAGScheduler: Broadcasting large task binary with size 1300.8 KiB\n",
      "24/05/27 18:24:51 WARN DAGScheduler: Broadcasting large task binary with size 1301.4 KiB\n",
      "24/05/27 18:24:52 WARN DAGScheduler: Broadcasting large task binary with size 1302.5 KiB\n",
      "24/05/27 18:24:53 WARN DAGScheduler: Broadcasting large task binary with size 1304.7 KiB\n",
      "24/05/27 18:24:54 WARN DAGScheduler: Broadcasting large task binary with size 1308.9 KiB\n",
      "24/05/27 18:24:55 WARN DAGScheduler: Broadcasting large task binary with size 1316.2 KiB\n",
      "24/05/27 18:24:57 WARN DAGScheduler: Broadcasting large task binary with size 1327.0 KiB\n",
      "24/05/27 18:24:58 WARN DAGScheduler: Broadcasting large task binary with size 1326.4 KiB\n",
      "24/05/27 18:24:59 WARN DAGScheduler: Broadcasting large task binary with size 1326.9 KiB\n",
      "24/05/27 18:25:00 WARN DAGScheduler: Broadcasting large task binary with size 1327.5 KiB\n",
      "24/05/27 18:25:02 WARN DAGScheduler: Broadcasting large task binary with size 1328.6 KiB\n",
      "24/05/27 18:25:03 WARN DAGScheduler: Broadcasting large task binary with size 1330.8 KiB\n",
      "24/05/27 18:25:04 WARN DAGScheduler: Broadcasting large task binary with size 1335.0 KiB\n",
      "24/05/27 18:25:05 WARN DAGScheduler: Broadcasting large task binary with size 1341.8 KiB\n",
      "24/05/27 18:25:07 WARN DAGScheduler: Broadcasting large task binary with size 1353.1 KiB\n",
      "24/05/27 18:25:08 WARN DAGScheduler: Broadcasting large task binary with size 1352.5 KiB\n",
      "24/05/27 18:25:09 WARN DAGScheduler: Broadcasting large task binary with size 1353.0 KiB\n",
      "24/05/27 18:25:10 WARN DAGScheduler: Broadcasting large task binary with size 1353.5 KiB\n",
      "24/05/27 18:25:11 WARN DAGScheduler: Broadcasting large task binary with size 1354.7 KiB\n",
      "24/05/27 18:25:13 WARN DAGScheduler: Broadcasting large task binary with size 1356.9 KiB\n",
      "24/05/27 18:25:14 WARN DAGScheduler: Broadcasting large task binary with size 1361.3 KiB\n",
      "24/05/27 18:25:15 WARN DAGScheduler: Broadcasting large task binary with size 1368.1 KiB\n",
      "24/05/27 18:25:16 WARN DAGScheduler: Broadcasting large task binary with size 1378.2 KiB\n",
      "24/05/27 18:25:18 WARN DAGScheduler: Broadcasting large task binary with size 1377.0 KiB\n",
      "24/05/27 18:25:19 WARN DAGScheduler: Broadcasting large task binary with size 1377.5 KiB\n",
      "24/05/27 18:25:20 WARN DAGScheduler: Broadcasting large task binary with size 1378.1 KiB\n",
      "24/05/27 18:25:22 WARN DAGScheduler: Broadcasting large task binary with size 1379.2 KiB\n",
      "24/05/27 18:25:23 WARN DAGScheduler: Broadcasting large task binary with size 1381.4 KiB\n",
      "24/05/27 18:25:24 WARN DAGScheduler: Broadcasting large task binary with size 1385.6 KiB\n",
      "24/05/27 18:25:26 WARN DAGScheduler: Broadcasting large task binary with size 1392.4 KiB\n",
      "24/05/27 18:25:27 WARN DAGScheduler: Broadcasting large task binary with size 1403.1 KiB\n",
      "24/05/27 18:25:32 WARN DAGScheduler: Broadcasting large task binary with size 1375.4 KiB\n",
      "24/05/27 18:25:35 WARN DAGScheduler: Broadcasting large task binary with size 1387.9 KiB\n",
      "24/05/27 18:25:38 WARN DAGScheduler: Broadcasting large task binary with size 1387.9 KiB\n",
      "24/05/27 18:25:40 WARN DAGScheduler: Broadcasting large task binary with size 1387.9 KiB\n",
      "24/05/27 18:25:42 WARN DAGScheduler: Broadcasting large task binary with size 1387.9 KiB\n",
      "24/05/27 18:40:51 WARN DAGScheduler: Broadcasting large task binary with size 1004.1 KiB\n",
      "24/05/27 18:40:52 WARN DAGScheduler: Broadcasting large task binary with size 1014.0 KiB\n",
      "24/05/27 18:40:53 WARN DAGScheduler: Broadcasting large task binary with size 1012.5 KiB\n",
      "24/05/27 18:40:54 WARN DAGScheduler: Broadcasting large task binary with size 1012.9 KiB\n",
      "24/05/27 18:40:56 WARN DAGScheduler: Broadcasting large task binary with size 1013.5 KiB\n",
      "24/05/27 18:40:57 WARN DAGScheduler: Broadcasting large task binary with size 1014.6 KiB\n",
      "24/05/27 18:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1016.6 KiB\n",
      "24/05/27 18:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1020.5 KiB\n",
      "24/05/27 18:41:00 WARN DAGScheduler: Broadcasting large task binary with size 1027.6 KiB\n",
      "24/05/27 18:41:01 WARN DAGScheduler: Broadcasting large task binary with size 1037.6 KiB\n",
      "24/05/27 18:41:02 WARN DAGScheduler: Broadcasting large task binary with size 1036.2 KiB\n",
      "24/05/27 18:41:03 WARN DAGScheduler: Broadcasting large task binary with size 1036.6 KiB\n",
      "24/05/27 18:41:04 WARN DAGScheduler: Broadcasting large task binary with size 1037.2 KiB\n",
      "24/05/27 18:41:05 WARN DAGScheduler: Broadcasting large task binary with size 1038.3 KiB\n",
      "24/05/27 18:41:06 WARN DAGScheduler: Broadcasting large task binary with size 1040.3 KiB\n",
      "24/05/27 18:41:07 WARN DAGScheduler: Broadcasting large task binary with size 1044.2 KiB\n",
      "24/05/27 18:41:08 WARN DAGScheduler: Broadcasting large task binary with size 1051.3 KiB\n",
      "24/05/27 18:41:09 WARN DAGScheduler: Broadcasting large task binary with size 1061.3 KiB\n",
      "24/05/27 18:41:10 WARN DAGScheduler: Broadcasting large task binary with size 1060.0 KiB\n",
      "24/05/27 18:41:12 WARN DAGScheduler: Broadcasting large task binary with size 1060.5 KiB\n",
      "24/05/27 18:41:13 WARN DAGScheduler: Broadcasting large task binary with size 1061.1 KiB\n",
      "24/05/27 18:41:14 WARN DAGScheduler: Broadcasting large task binary with size 1062.2 KiB\n",
      "24/05/27 18:41:15 WARN DAGScheduler: Broadcasting large task binary with size 1064.4 KiB\n",
      "24/05/27 18:41:17 WARN DAGScheduler: Broadcasting large task binary with size 1067.7 KiB\n",
      "24/05/27 18:41:18 WARN DAGScheduler: Broadcasting large task binary with size 1073.7 KiB\n",
      "24/05/27 18:41:19 WARN DAGScheduler: Broadcasting large task binary with size 1082.7 KiB\n",
      "24/05/27 18:41:20 WARN DAGScheduler: Broadcasting large task binary with size 1081.8 KiB\n",
      "24/05/27 18:41:21 WARN DAGScheduler: Broadcasting large task binary with size 1082.3 KiB\n",
      "24/05/27 18:41:22 WARN DAGScheduler: Broadcasting large task binary with size 1082.9 KiB\n",
      "24/05/27 18:41:23 WARN DAGScheduler: Broadcasting large task binary with size 1084.0 KiB\n",
      "24/05/27 18:41:24 WARN DAGScheduler: Broadcasting large task binary with size 1086.2 KiB\n",
      "24/05/27 18:41:25 WARN DAGScheduler: Broadcasting large task binary with size 1090.4 KiB\n",
      "24/05/27 18:41:26 WARN DAGScheduler: Broadcasting large task binary with size 1097.2 KiB\n",
      "24/05/27 18:41:28 WARN DAGScheduler: Broadcasting large task binary with size 1107.2 KiB\n",
      "24/05/27 18:41:29 WARN DAGScheduler: Broadcasting large task binary with size 1105.6 KiB\n",
      "24/05/27 18:41:30 WARN DAGScheduler: Broadcasting large task binary with size 1106.0 KiB\n",
      "24/05/27 18:41:31 WARN DAGScheduler: Broadcasting large task binary with size 1106.6 KiB\n",
      "24/05/27 18:41:32 WARN DAGScheduler: Broadcasting large task binary with size 1107.7 KiB\n",
      "24/05/27 18:41:33 WARN DAGScheduler: Broadcasting large task binary with size 1109.9 KiB\n",
      "24/05/27 18:41:34 WARN DAGScheduler: Broadcasting large task binary with size 1113.2 KiB\n",
      "24/05/27 18:41:35 WARN DAGScheduler: Broadcasting large task binary with size 1118.3 KiB\n",
      "24/05/27 18:41:36 WARN DAGScheduler: Broadcasting large task binary with size 1125.7 KiB\n",
      "24/05/27 18:41:38 WARN DAGScheduler: Broadcasting large task binary with size 1124.8 KiB\n",
      "24/05/27 18:41:39 WARN DAGScheduler: Broadcasting large task binary with size 1125.3 KiB\n",
      "24/05/27 18:41:40 WARN DAGScheduler: Broadcasting large task binary with size 1125.8 KiB\n",
      "24/05/27 18:41:41 WARN DAGScheduler: Broadcasting large task binary with size 1127.0 KiB\n",
      "24/05/27 18:41:42 WARN DAGScheduler: Broadcasting large task binary with size 1129.2 KiB\n",
      "24/05/27 18:41:43 WARN DAGScheduler: Broadcasting large task binary with size 1133.3 KiB\n",
      "24/05/27 18:41:44 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "24/05/27 18:41:45 WARN DAGScheduler: Broadcasting large task binary with size 1149.4 KiB\n",
      "24/05/27 18:41:46 WARN DAGScheduler: Broadcasting large task binary with size 1148.1 KiB\n",
      "24/05/27 18:41:48 WARN DAGScheduler: Broadcasting large task binary with size 1148.5 KiB\n",
      "24/05/27 18:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1149.1 KiB\n",
      "24/05/27 18:41:50 WARN DAGScheduler: Broadcasting large task binary with size 1150.3 KiB\n",
      "24/05/27 18:41:51 WARN DAGScheduler: Broadcasting large task binary with size 1152.5 KiB\n",
      "24/05/27 18:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1156.9 KiB\n",
      "24/05/27 18:41:53 WARN DAGScheduler: Broadcasting large task binary with size 1163.6 KiB\n",
      "24/05/27 18:41:54 WARN DAGScheduler: Broadcasting large task binary with size 1172.9 KiB\n",
      "24/05/27 18:41:55 WARN DAGScheduler: Broadcasting large task binary with size 1171.2 KiB\n",
      "24/05/27 18:41:56 WARN DAGScheduler: Broadcasting large task binary with size 1171.7 KiB\n",
      "24/05/27 18:41:57 WARN DAGScheduler: Broadcasting large task binary with size 1172.3 KiB\n",
      "24/05/27 18:41:59 WARN DAGScheduler: Broadcasting large task binary with size 1173.4 KiB\n",
      "24/05/27 18:42:00 WARN DAGScheduler: Broadcasting large task binary with size 1175.6 KiB\n",
      "24/05/27 18:42:01 WARN DAGScheduler: Broadcasting large task binary with size 1179.8 KiB\n",
      "24/05/27 18:42:02 WARN DAGScheduler: Broadcasting large task binary with size 1186.8 KiB\n",
      "24/05/27 18:42:03 WARN DAGScheduler: Broadcasting large task binary with size 1196.4 KiB\n",
      "24/05/27 18:42:05 WARN DAGScheduler: Broadcasting large task binary with size 1195.6 KiB\n",
      "24/05/27 18:42:06 WARN DAGScheduler: Broadcasting large task binary with size 1196.1 KiB\n",
      "24/05/27 18:42:07 WARN DAGScheduler: Broadcasting large task binary with size 1196.6 KiB\n",
      "24/05/27 18:42:08 WARN DAGScheduler: Broadcasting large task binary with size 1197.8 KiB\n",
      "24/05/27 18:42:09 WARN DAGScheduler: Broadcasting large task binary with size 1200.0 KiB\n",
      "24/05/27 18:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1203.5 KiB\n",
      "24/05/27 18:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1209.2 KiB\n",
      "24/05/27 18:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1217.7 KiB\n",
      "24/05/27 18:42:14 WARN DAGScheduler: Broadcasting large task binary with size 1216.7 KiB\n",
      "24/05/27 18:42:15 WARN DAGScheduler: Broadcasting large task binary with size 1217.2 KiB\n",
      "24/05/27 18:42:16 WARN DAGScheduler: Broadcasting large task binary with size 1217.8 KiB\n",
      "24/05/27 18:42:18 WARN DAGScheduler: Broadcasting large task binary with size 1218.9 KiB\n",
      "24/05/27 18:42:20 WARN DAGScheduler: Broadcasting large task binary with size 1220.9 KiB\n",
      "24/05/27 18:42:21 WARN DAGScheduler: Broadcasting large task binary with size 1224.8 KiB\n",
      "24/05/27 18:42:22 WARN DAGScheduler: Broadcasting large task binary with size 1231.8 KiB\n",
      "24/05/27 18:42:23 WARN DAGScheduler: Broadcasting large task binary with size 1241.4 KiB\n",
      "24/05/27 18:42:24 WARN DAGScheduler: Broadcasting large task binary with size 1239.3 KiB\n",
      "24/05/27 18:42:25 WARN DAGScheduler: Broadcasting large task binary with size 1239.8 KiB\n",
      "24/05/27 18:42:27 WARN DAGScheduler: Broadcasting large task binary with size 1240.4 KiB\n",
      "24/05/27 18:42:28 WARN DAGScheduler: Broadcasting large task binary with size 1241.5 KiB\n",
      "24/05/27 18:42:29 WARN DAGScheduler: Broadcasting large task binary with size 1243.5 KiB\n",
      "24/05/27 18:42:30 WARN DAGScheduler: Broadcasting large task binary with size 1247.3 KiB\n",
      "24/05/27 18:42:31 WARN DAGScheduler: Broadcasting large task binary with size 1253.8 KiB\n",
      "24/05/27 18:42:33 WARN DAGScheduler: Broadcasting large task binary with size 1262.9 KiB\n",
      "24/05/27 18:42:37 WARN DAGScheduler: Broadcasting large task binary with size 1233.9 KiB\n",
      "24/05/27 18:42:40 WARN DAGScheduler: Broadcasting large task binary with size 1246.5 KiB\n",
      "24/05/27 18:42:42 WARN DAGScheduler: Broadcasting large task binary with size 1246.5 KiB\n",
      "24/05/27 18:42:44 WARN DAGScheduler: Broadcasting large task binary with size 1246.5 KiB\n",
      "24/05/27 18:42:45 WARN DAGScheduler: Broadcasting large task binary with size 1246.5 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier Composite Score: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Composite Score: 0.7952\n",
      "Best Model: LogisticRegression\n",
      "Best Model Composite Score: 0.8412\n",
      "Best Model Metrics - AUC: 0.8853, Accuracy: 0.8118, Precision: 0.8118, Recall: 0.8118, F1-Score: 0.8118\n",
      "Selected Regularization Parameter: 0.1\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5587f40-ecc4-4c10-b2a8-849c1a8143a4",
   "metadata": {},
   "source": [
    "The best model is LogisticRegression with metrics - AUC: 0.8853, Accuracy: 0.8118, Precision: 0.8118, Recall: 0.8118, F1-Score: 0.8118\n",
    "The selected regularization parameter was 0.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
